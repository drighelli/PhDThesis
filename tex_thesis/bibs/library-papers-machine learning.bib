Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Divina2012c,
abstract = {Biclustering is becoming a popular technique for the study of gene expression data. This is mainly due to the capability of biclustering to address the data using various dimensions simultaneously, as opposed to clustering, which can use only one dimension at the time. Different heuristics have been proposed in order to discover interesting biclusters in data. Such heuristics have one common characteristic: they are guided by a measure that determines the quality of biclusters. It follows that defining such a measure is probably the most important aspect. One of the popular quality measure is the mean squared residue (MSR). However, it has been proven that MSR fails at identifying some kind of patterns. This motivates us to introduce a novel measure, called virtual error (VE), that overcomes this limitation. Results obtained by using VE confirm that it can identify interesting patterns that could not be found by MSR.},
author = {Divina, Federico and Pontes, Beatriz and Gir{\'{a}}ldez, Ra{\'{u}}l and Aguilar-Ruiz, Jes{\'{u}}s S},
doi = {10.1016/j.compbiomed.2011.11.015},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Divina et al. - 2012 - An effective measure for assessing the quality of biclusters.pdf:pdf},
issn = {1879-0534},
journal = {Computers in biology and medicine},
keywords = {Algorithms,Cluster Analysis,Computational Biology,Computational Biology: methods,Databases,Gene Expression Profiling,Gene Expression Profiling: methods,Genetic,Humans,biclustering,learning,machine,quality},
mendeley-tags = {biclustering,learning,machine,quality},
number = {2},
pages = {245--56},
pmid = {22196882},
title = {{An effective measure for assessing the quality of biclusters.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22196882},
volume = {42},
year = {2012}
}
@article{Breiman2001c,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the corre- lation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth Interna- tional conference, ∗∗∗, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression. Keywords:},
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1023{\%}2FA{\%}3A1010933404324},
author = {Breiman, L},
doi = {10.1023/A:1010933404324},
eprint = {/dx.doi.org/10.1023{\%}2FA{\%}3A1010933404324},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breiman - 2001 - Random forests.pdf:pdf},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Machine learning},
keywords = {classification,ensemble,forest,random,regression},
mendeley-tags = {forest,random},
pages = {5--32},
pmid = {21816105},
primaryClass = {http:},
title = {{Random forests}},
url = {http://link.springer.com/article/10.1023/A:1010933404324},
year = {2001}
}
@article{Qi2012c,
abstract = {Modern biology has experienced an increased use of machine learning techniques for large scale and complex biological data analysis. In the area of Bioinformatics, the Random Forest (RF) 6 technique, which includes an ensemble of decision trees and incorporates feature selection and interactions naturally in the learning process, is a popular choice. It is nonparametric, interpretable, efficient, and has high prediction accuracy for many types of data. Recent work in computational biology has seen an increased use of RF, owing to its unique advantages in dealing with small sample size, high-dimensional feature space, and complex data structures.},
author = {Qi, Yanjun},
doi = {10.1007/978-1-4419-9326-7_11},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qi - 2012 - Random Forest for Bioinformatics.pdf:pdf},
isbn = {978-1-4419-9325-0},
journal = {Ensemble Machine Learning},
keywords = {forest,random},
mendeley-tags = {forest,random},
pages = {307--323},
title = {{Random Forest for Bioinformatics}},
year = {2012}
}
@article{Flores2013c,
abstract = {BACKGROUND: One of the emerging techniques for performing the analysis of the DNA microarray data known as biclustering is the search of subsets of genes and conditions which are coherently expressed. These subgroups provide clues about the main biological processes. Until now, different approaches to this problem have been proposed. Most of them use the mean squared residue as quality measure but relevant and interesting patterns can not be detected such as shifting, or scaling patterns. Furthermore, recent papers show that there exist new coherence patterns involved in different kinds of cancer and tumors such as inverse relationships between genes which can not be captured.$\backslash$n$\backslash$nRESULTS: The proposed measure is called Spearman's biclustering measure (SBM) which performs an estimation of the quality of a bicluster based on the non-linear correlation among genes and conditions simultaneously. The search of biclusters is performed by using a evolutionary technique called estimation of distribution algorithms which uses the SBM measure as fitness function. This approach has been examined from different points of view by using artificial and real microarrays. The assessment process has involved the use of quality indexes, a set of bicluster patterns of reference including new patterns and a set of statistical tests. It has been also examined the performance using real microarrays and comparing to different algorithmic approaches such as Bimax, CC, OPSM, Plaid and xMotifs.$\backslash$n$\backslash$nCONCLUSIONS: SBM shows several advantages such as the ability to recognize more complex coherence patterns such as shifting, scaling and inversion and the capability to selectively marginalize genes and conditions depending on the statistical significance.},
author = {Flores, Jose L and Inza, I{\~{n}}aki and Larra{\~{n}}aga, Pedro and Calvo, Borja},
doi = {10.1016/j.cmpb.2013.07.025},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Flores et al. - 2013 - A new measure for gene expression biclustering based on non-parametric correlation.pdf:pdf},
isbn = {0169-2607},
issn = {1872-7565},
journal = {Computer methods and programs in biomedicine},
keywords = {Algorithms,Cluster Analysis,Gene Expression,biclustering,learning,machine},
mendeley-tags = {biclustering,learning,machine},
number = {3},
pages = {367--97},
pmid = {24079964},
title = {{A new measure for gene expression biclustering based on non-parametric correlation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24079964},
volume = {112},
year = {2013}
}
@article{Yan2013c,
abstract = {Biclustering is an important tool to find patterns in a microarray data matrix by simultaneous classification in two dimensions of genes and conditions. Unlike most existed biclustering algorithms where almost all genes and conditions are involved in the clustering process even if they contribute little to a bicluster, we propose to perform the biclustering operation only in related genes and conditions of a given bicluster type. In our algorithm, the gene expression matrix is first partitioned to stable and unstable submatrices in both row and column directions by inspecting the similarity between the row (or column) vector and the full 1s vector, then the related genes and conditions of a given type of biclusters are extracted by inspecting the row or column pairs in the corresponding stable or unstable submatrices, finally the resulted biclusters of any type are obtained by performing clustering analysis in the extracted related genes and conditions. Additionally, a novel strategy for estimating the missing data in the gene expression matrix is also presented based on the James-Stein and kernel estimation principle where the estimation matrix is obtained with the k means algorithm. Experimental results show excellent performance of our algorithm both in missing data estimation and biclustering. ?? 2012 Elsevier Ltd. All rights reserved.},
author = {Yan, Dechun and Wang, Jiajun},
doi = {10.1016/j.patcog.2012.09.028},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, Wang - 2013 - Biclustering of gene expression data based on related genes and conditions extraction.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Biclustering,Gene expression data,Microarray,Missing data estimation,biclustering,learning,machine},
mendeley-tags = {biclustering,learning,machine},
number = {4},
pages = {1170--1182},
publisher = {Elsevier},
title = {{Biclustering of gene expression data based on related genes and conditions extraction}},
url = {http://dx.doi.org/10.1016/j.patcog.2012.09.028},
volume = {46},
year = {2013}
}
@article{Liang2013c,
abstract = {BACKGROUND: Microarray technology is widely used in cancer diagnosis. Successfully identifying gene biomarkers will significantly help to classify different cancer types and improve the prediction accuracy. The regularization approach is one of the effective methods for gene selection in microarray data, which generally contain a large number of genes and have a small number of samples. In recent years, various approaches have been developed for gene selection of microarray data. Generally, they are divided into three categories: filter, wrapper and embedded methods. Regularization methods are an important embedded technique and perform both continuous shrinkage and automatic gene selection simultaneously. Recently, there is growing interest in applying the regularization techniques in gene selection. The popular regularization technique is Lasso (L1), and many L1 type regularization terms have been proposed in the recent years. Theoretically, the Lq type regularization with the lower value of q would lead to better solutions with more sparsity. Moreover, the L1/2 regularization can be taken as a representative of Lq (0 {\textless}q {\textless} 1) regularizations and has been demonstrated many attractive properties.$\backslash$n$\backslash$nRESULTS: In this work, we investigate a sparse logistic regression with the L1/2 penalty for gene selection in cancer classification problems, and propose a coordinate descent algorithm with a new univariate half thresholding operator to solve the L1/2 penalized logistic regression. Experimental results on artificial and microarray data demonstrate the effectiveness of our proposed approach compared with other regularization methods. Especially, for 4 publicly available gene expression datasets, the L1/2 regularization method achieved its success using only about 2 to 14 predictors (genes), compared to about 6 to 38 genes for ordinary L1 and elastic net regularization approaches.$\backslash$n$\backslash$nCONCLUSIONS: From our evaluations, it is clear that the sparse logistic regression with the L1/2 penalty achieves higher classification accuracy than those of ordinary L1 and elastic net regularization approaches, while fewer but informative genes are selected. This is an important consideration for screening and diagnostic applications, where the goal is often to develop an accurate test using as few features as possible in order to control cost. Therefore, the sparse logistic regression with the L1/2 penalty is effective technique for gene selection in real classification problems.},
author = {Liang, Yong and Liu, Cheng and Luan, Xin-Ze and Leung, Kwong-Sak and Chan, Tak-Ming and Xu, Zong-Ben and Zhang, Hai},
doi = {10.1186/1471-2105-14-198},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2013 - Sparse logistic regression with a L12 penalty for gene selection in cancer classification.pdf:pdf},
isbn = {1471-2105 (Electronic)$\backslash$r1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Algorithms,Gene Expression Regulation,Genetic Markers,Humans,Logistic Models,Neoplasms,Neoplasms: classification,Neoplasms: genetics,Neoplasms: metabolism,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,feature,selection},
mendeley-tags = {feature,selection},
number = {1},
pages = {198},
pmid = {23777239},
title = {{Sparse logistic regression with a L1/2 penalty for gene selection in cancer classification.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3718705{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2013}
}
@article{Frenay2013c,
abstract = {Feature selection is an important preprocessing step for many high-dimensional regression problems. One of the most common strategies is to select a relevant feature subset based on the mutual information criterion. However, no connection has been established yet between the use of mutual information and a regression error criterion in the machine learning literature. This is obviously an important lack, since minimising such a criterion is eventually the objective one is interested in. This paper demonstrates that under some reasonable assumptions, features selected with the mutual information criterion are the ones minimising the mean squared error and the mean absolute error. On the contrary, it is also shown that the mutual information criterion can fail in selecting optimal features in some situations that we characterise. The theoretical developments presented in this work are expected to lead in practice to a critical and efficient use of the mutual information for feature selection. {\textcopyright} 2013 Elsevier Ltd.},
author = {Fr{\'{e}}nay, Beno{\^{i}}t and Doquire, Gauthier and Verleysen, Michel},
doi = {10.1016/j.neunet.2013.07.003},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fr{\'{e}}nay, Doquire, Verleysen - 2013 - Is mutual information adequate for feature selection in regression.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Feature selection,MAE,MSE,Mutual information,Regression,feature,information,mutual,regression,selection},
mendeley-tags = {feature,information,mutual,regression,selection},
pages = {1--7},
pmid = {23892907},
title = {{Is mutual information adequate for feature selection in regression?}},
url = {http://dx.doi.org/10.1016/j.neunet.2013.07.003},
volume = {48},
year = {2013}
}
@article{DeRidder2013c,
author = {de Ridder, D. and de Ridder, J. and Reinders, M. J. T.},
doi = {10.1093/bib/bbt020},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Ridder, de Ridder, Reinders - 2013 - Pattern recognition in bioinformatics.pdf:pdf},
issn = {1467-5463},
journal = {Briefings in Bioinformatics},
keywords = {bioinformatics,classification,clustering,dimensionality reduction,feature,pattern,pattern recognition,recognition,selection},
mendeley-tags = {feature,pattern,recognition,selection},
number = {5},
pages = {633--647},
title = {{Pattern recognition in bioinformatics}},
url = {http://bib.oxfordjournals.org/cgi/doi/10.1093/bib/bbt020},
volume = {14},
year = {2013}
}
@article{Saeys2007c,
abstract = {Feature selection techniques have become an apparent need in many bioinformatics applications. In addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques. In this article, we make the interested reader aware of the possibilities of feature selection, providing a basic taxonomy of feature selection techniques, and discussing their use, variety and potential in a number of both common as well as upcoming bioinformatics applications.},
author = {Saeys, Yvan and Inza, I{\~{n}}aki and Larra{\~{n}}aga, Pedro},
doi = {10.1093/bioinformatics/btm344},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saeys, Inza, Larra{\~{n}}aga - 2007 - A review of feature selection techniques in bioinformatics.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {feature,review,selection},
mendeley-tags = {feature,review,selection},
number = {19},
pages = {2507--2517},
pmid = {17720704},
title = {{A review of feature selection techniques in bioinformatics}},
volume = {23},
year = {2007}
}
@article{Eren2013c,
author = {Eren, K. and Deveci, M. and Kucuktunc, O. and Catalyurek, U. V.},
doi = {10.1093/bib/bbs032},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eren et al. - 2013 - A comparative analysis of biclustering algorithms for gene expression data.pdf:pdf},
issn = {1467-5463},
journal = {Briefings in Bioinformatics},
keywords = {biclustering,clustering,gene expression,learning,machine,microarray,review},
mendeley-tags = {biclustering,learning,machine,review},
number = {3},
pages = {279--292},
title = {{A comparative analysis of biclustering algorithms for gene expression data}},
url = {http://bib.oxfordjournals.org/cgi/doi/10.1093/bib/bbs032},
volume = {14},
year = {2013}
}
@article{Ding2012c,
abstract = {MOTIVATION: The study of cancer genomes now routinely involves using next-generation sequencing technology (NGS) to profile tumours for single nucleotide variant (SNV) somatic mutations. However, surprisingly few published bioinformatics methods exist for the specific purpose of identifying somatic mutations from NGS data and existing tools are often inaccurate, yielding intolerably high false prediction rates. As such, the computational problem of accurately inferring somatic mutations from paired tumour/normal NGS data remains an unsolved challenge.$\backslash$n$\backslash$nRESULTS: We present the comparison of four standard supervised machine learning algorithms for the purpose of somatic SNV prediction in tumour/normal NGS experiments. To evaluate these approaches (random forest, Bayesian additive regression tree, support vector machine and logistic regression), we constructed 106 features representing 3369 candidate somatic SNVs from 48 breast cancer genomes, originally predicted with naive methods and subsequently revalidated to establish ground truth labels. We trained the classifiers on this data (consisting of 1015 true somatic mutations and 2354 non-somatic mutation positions) and conducted a rigorous evaluation of these methods using a cross-validation framework and hold-out test NGS data from both exome capture and whole genome shotgun platforms. All learning algorithms employing predictive discriminative approaches with feature selection improved the predictive accuracy over standard approaches by statistically significant margins. In addition, using unsupervised clustering of the ground truth 'false positive' predictions, we noted several distinct classes and present evidence suggesting non-overlapping sources of technical artefacts illuminating important directions for future study.$\backslash$n$\backslash$nAVAILABILITY: Software called MutationSeq and datasets are available from http://compbio.bccrc.ca.},
author = {Ding, Jiarui and Bashashati, Ali and Roth, Andrew and Oloumi, Arusha and Tse, Kane and Zeng, Thomas and Haffari, Gholamreza and Hirst, Martin and Marra, Marco a. and Condon, Anne and Aparicio, Samuel and Shah, Sohrab P.},
doi = {10.1093/bioinformatics/btr629},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2012 - Feature-based classifiers for somatic mutation detection in tumour-normal paired sequencing data.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {feature,selection},
mendeley-tags = {feature,selection},
number = {2},
pages = {167--175},
pmid = {22084253},
title = {{Feature-based classifiers for somatic mutation detection in tumour-normal paired sequencing data}},
volume = {28},
year = {2012}
}
@article{Cheng2000c,
abstract = {An efficient node-deletion algorithm is introduced to find submatrices in expression data that have low mean squared residue scores and it is shown to perform well in finding co-regulation patterns in yeast and human. This introduces "biclustering", or simultaneous clustering of both genes and conditions, to knowledge discovery from expression data. This approach overcomes some problems associated with traditional clustering methods, by allowing automatic discovery of similarity based on a subset of attributes, simultaneous clustering of genes and conditions, and overlapped grouping that provides a better representation for genes with multiple functions or regulated by many factors.},
author = {Cheng, Y and Church, G M},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng, Church - 2000 - Biclustering of expression data.pdf:pdf},
isbn = {1553-0833 (Print)$\backslash$r1553-0833 (Linking)},
issn = {1553-0833},
journal = {Proceedings / ... International Conference on Intelligent Systems for Molecular Biology ; ISMB. International Conference on Intelligent Systems for Molecular Biology},
keywords = {biclustering,learning,machine},
mendeley-tags = {biclustering,learning,machine},
pages = {93--103},
pmid = {10977070},
title = {{Biclustering of expression data.}},
volume = {8},
year = {2000}
}
@article{Boulesteix2012c,
abstract = {The random forest (RF) algorithm by Leo Breiman has become a standard data analysis tool in bioinformatics. It has shown excellent performance in settings where the number of variables is much larger than the number of observations, can cope with complex interaction structures as well as highly correlated variables and return measures of variable importance. This paper synthesizes 10 years of RF development with emphasis on applications to bioinformatics and computational biology. Special attention is paid to practical aspects such as the selection of parameters, available RF implementations, and important pitfalls and biases of RF and its variable importance measures (VIMs). The paper surveys recent developments of the methodology relevant to bioinformatics as well as some representative examples of RF applications in this context and possible directions for future research.},
author = {Boulesteix, Anne Laure and Janitza, Silke and Kruppa, Jochen and K{\"{o}}nig, Inke R.},
doi = {10.1002/widm.1072},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boulesteix et al. - 2012 - Overview of random forest methodology and practical guidance with emphasis on computational biology and bioin.pdf:pdf},
isbn = {1942-4795},
issn = {19424787},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
keywords = {forest,overview,random},
mendeley-tags = {forest,overview,random},
number = {6},
pages = {493--507},
pmid = {1000183064},
title = {{Overview of random forest methodology and practical guidance with emphasis on computational biology and bioinformatics}},
volume = {2},
year = {2012}
}
@article{Pontes2015c,
author = {Pontes, Beatriz and Gir{\'{a}}ldez, Ra{\'{u}}l and Aguilar-Ruiz, Jes{\'{u}}s S.},
doi = {10.1016/j.jbi.2015.06.028},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pontes, Gir{\'{a}}ldez, Aguilar-Ruiz - 2015 - Biclustering on expression data A review.pdf:pdf},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {biclustering,learning,machine,review},
mendeley-tags = {biclustering,learning,machine,review},
pages = {163--180},
publisher = {Elsevier Inc.},
title = {{Biclustering on expression data: A review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1532046415001380},
volume = {57},
year = {2015}
}
@article{Oghabian2014c,
author = {Oghabian, Ali and Kilpinen, Sami and Hautaniemi, Sampsa and Czeizler, Elena},
doi = {10.1371/journal.pone.0090801},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oghabian et al. - 2014 - Biclustering Methods Biological Relevance and Application in Gene Expression Analysis.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
keywords = {biclustering,learning,machine,review},
mendeley-tags = {biclustering,learning,machine,review},
number = {3},
pages = {e90801},
title = {{Biclustering Methods: Biological Relevance and Application in Gene Expression Analysis}},
url = {http://dx.plos.org/10.1371/journal.pone.0090801},
volume = {9},
year = {2014}
}
@article{Zhao2012c,
abstract = {Biclustering analysis is a useful methodology to discover the local coherent patterns hidden in a data matrix. Unlike the traditional clustering procedure, which searches for groups of coherent patterns using the entire feature set, biclustering performs simultaneous pattern classification in both row and column directions in a data matrix. The technique has found useful applications in many fields but notably in bioinformatics. In this paper, we give an overview of the biclustering problem and review some existing biclustering algorithms in terms of their underlying methodology, search strategy, detected bicluster patterns, and validation strategies. Moreover, we show that geometry of biclustering patterns can be used to solve biclustering problems effectively. Well-known methods in signal and image analysis, such as the Hough transform and relaxation labeling, can be employed to detect the geometrical biclustering patterns. We present performance evaluation results for several of the well known biclustering algorithms, on both artificial and real gene expression datasets. Finally, several interesting applications of biclustering are discussed.},
author = {Zhao, H Y and Liew, A W C and Wang, D Z and Yan, H},
doi = {10.2174/157489312799304413},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2012 - Biclustering Analysis for Pattern Discovery Current Techniques, Comparative Studies and Applications.pdf:pdf},
isbn = {6175552806},
issn = {15748936},
journal = {Current Bioinformatics},
keywords = {biclustering,biclustering clustering gene expression data analy,learning,machine},
mendeley-tags = {biclustering,learning,machine},
pages = {43----55 ST ---- Biclustering Analysis for Pattern Dis},
title = {{Biclustering Analysis for Pattern Discovery: Current Techniques, Comparative Studies and Applications}},
volume = {7},
year = {2012}
}
