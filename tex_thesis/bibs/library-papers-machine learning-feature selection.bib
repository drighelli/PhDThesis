Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Ding2012c,
abstract = {MOTIVATION: The study of cancer genomes now routinely involves using next-generation sequencing technology (NGS) to profile tumours for single nucleotide variant (SNV) somatic mutations. However, surprisingly few published bioinformatics methods exist for the specific purpose of identifying somatic mutations from NGS data and existing tools are often inaccurate, yielding intolerably high false prediction rates. As such, the computational problem of accurately inferring somatic mutations from paired tumour/normal NGS data remains an unsolved challenge.$\backslash$n$\backslash$nRESULTS: We present the comparison of four standard supervised machine learning algorithms for the purpose of somatic SNV prediction in tumour/normal NGS experiments. To evaluate these approaches (random forest, Bayesian additive regression tree, support vector machine and logistic regression), we constructed 106 features representing 3369 candidate somatic SNVs from 48 breast cancer genomes, originally predicted with naive methods and subsequently revalidated to establish ground truth labels. We trained the classifiers on this data (consisting of 1015 true somatic mutations and 2354 non-somatic mutation positions) and conducted a rigorous evaluation of these methods using a cross-validation framework and hold-out test NGS data from both exome capture and whole genome shotgun platforms. All learning algorithms employing predictive discriminative approaches with feature selection improved the predictive accuracy over standard approaches by statistically significant margins. In addition, using unsupervised clustering of the ground truth 'false positive' predictions, we noted several distinct classes and present evidence suggesting non-overlapping sources of technical artefacts illuminating important directions for future study.$\backslash$n$\backslash$nAVAILABILITY: Software called MutationSeq and datasets are available from http://compbio.bccrc.ca.},
author = {Ding, Jiarui and Bashashati, Ali and Roth, Andrew and Oloumi, Arusha and Tse, Kane and Zeng, Thomas and Haffari, Gholamreza and Hirst, Martin and Marra, Marco a. and Condon, Anne and Aparicio, Samuel and Shah, Sohrab P.},
doi = {10.1093/bioinformatics/btr629},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - 2012 - Feature-based classifiers for somatic mutation detection in tumour-normal paired sequencing data.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {feature,selection},
mendeley-tags = {feature,selection},
number = {2},
pages = {167--175},
pmid = {22084253},
title = {{Feature-based classifiers for somatic mutation detection in tumour-normal paired sequencing data}},
volume = {28},
year = {2012}
}
@article{Liang2013c,
abstract = {BACKGROUND: Microarray technology is widely used in cancer diagnosis. Successfully identifying gene biomarkers will significantly help to classify different cancer types and improve the prediction accuracy. The regularization approach is one of the effective methods for gene selection in microarray data, which generally contain a large number of genes and have a small number of samples. In recent years, various approaches have been developed for gene selection of microarray data. Generally, they are divided into three categories: filter, wrapper and embedded methods. Regularization methods are an important embedded technique and perform both continuous shrinkage and automatic gene selection simultaneously. Recently, there is growing interest in applying the regularization techniques in gene selection. The popular regularization technique is Lasso (L1), and many L1 type regularization terms have been proposed in the recent years. Theoretically, the Lq type regularization with the lower value of q would lead to better solutions with more sparsity. Moreover, the L1/2 regularization can be taken as a representative of Lq (0 {\textless}q {\textless} 1) regularizations and has been demonstrated many attractive properties.$\backslash$n$\backslash$nRESULTS: In this work, we investigate a sparse logistic regression with the L1/2 penalty for gene selection in cancer classification problems, and propose a coordinate descent algorithm with a new univariate half thresholding operator to solve the L1/2 penalized logistic regression. Experimental results on artificial and microarray data demonstrate the effectiveness of our proposed approach compared with other regularization methods. Especially, for 4 publicly available gene expression datasets, the L1/2 regularization method achieved its success using only about 2 to 14 predictors (genes), compared to about 6 to 38 genes for ordinary L1 and elastic net regularization approaches.$\backslash$n$\backslash$nCONCLUSIONS: From our evaluations, it is clear that the sparse logistic regression with the L1/2 penalty achieves higher classification accuracy than those of ordinary L1 and elastic net regularization approaches, while fewer but informative genes are selected. This is an important consideration for screening and diagnostic applications, where the goal is often to develop an accurate test using as few features as possible in order to control cost. Therefore, the sparse logistic regression with the L1/2 penalty is effective technique for gene selection in real classification problems.},
author = {Liang, Yong and Liu, Cheng and Luan, Xin-Ze and Leung, Kwong-Sak and Chan, Tak-Ming and Xu, Zong-Ben and Zhang, Hai},
doi = {10.1186/1471-2105-14-198},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2013 - Sparse logistic regression with a L12 penalty for gene selection in cancer classification.pdf:pdf},
isbn = {1471-2105 (Electronic)$\backslash$r1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Algorithms,Gene Expression Regulation,Genetic Markers,Humans,Logistic Models,Neoplasms,Neoplasms: classification,Neoplasms: genetics,Neoplasms: metabolism,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,feature,selection},
mendeley-tags = {feature,selection},
number = {1},
pages = {198},
pmid = {23777239},
title = {{Sparse logistic regression with a L1/2 penalty for gene selection in cancer classification.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3718705{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2013}
}
@article{DeRidder2013c,
author = {de Ridder, D. and de Ridder, J. and Reinders, M. J. T.},
doi = {10.1093/bib/bbt020},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Ridder, de Ridder, Reinders - 2013 - Pattern recognition in bioinformatics.pdf:pdf},
issn = {1467-5463},
journal = {Briefings in Bioinformatics},
keywords = {bioinformatics,classification,clustering,dimensionality reduction,feature,pattern,pattern recognition,recognition,selection},
mendeley-tags = {feature,pattern,recognition,selection},
number = {5},
pages = {633--647},
title = {{Pattern recognition in bioinformatics}},
url = {http://bib.oxfordjournals.org/cgi/doi/10.1093/bib/bbt020},
volume = {14},
year = {2013}
}
@article{Frenay2013c,
abstract = {Feature selection is an important preprocessing step for many high-dimensional regression problems. One of the most common strategies is to select a relevant feature subset based on the mutual information criterion. However, no connection has been established yet between the use of mutual information and a regression error criterion in the machine learning literature. This is obviously an important lack, since minimising such a criterion is eventually the objective one is interested in. This paper demonstrates that under some reasonable assumptions, features selected with the mutual information criterion are the ones minimising the mean squared error and the mean absolute error. On the contrary, it is also shown that the mutual information criterion can fail in selecting optimal features in some situations that we characterise. The theoretical developments presented in this work are expected to lead in practice to a critical and efficient use of the mutual information for feature selection. {\textcopyright} 2013 Elsevier Ltd.},
author = {Fr{\'{e}}nay, Beno{\^{i}}t and Doquire, Gauthier and Verleysen, Michel},
doi = {10.1016/j.neunet.2013.07.003},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fr{\'{e}}nay, Doquire, Verleysen - 2013 - Is mutual information adequate for feature selection in regression.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Feature selection,MAE,MSE,Mutual information,Regression,feature,information,mutual,regression,selection},
mendeley-tags = {feature,information,mutual,regression,selection},
pages = {1--7},
pmid = {23892907},
title = {{Is mutual information adequate for feature selection in regression?}},
url = {http://dx.doi.org/10.1016/j.neunet.2013.07.003},
volume = {48},
year = {2013}
}
@article{Saeys2007c,
abstract = {Feature selection techniques have become an apparent need in many bioinformatics applications. In addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques. In this article, we make the interested reader aware of the possibilities of feature selection, providing a basic taxonomy of feature selection techniques, and discussing their use, variety and potential in a number of both common as well as upcoming bioinformatics applications.},
author = {Saeys, Yvan and Inza, I{\~{n}}aki and Larra{\~{n}}aga, Pedro},
doi = {10.1093/bioinformatics/btm344},
file = {:home/dario/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saeys, Inza, Larra{\~{n}}aga - 2007 - A review of feature selection techniques in bioinformatics.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {feature,review,selection},
mendeley-tags = {feature,review,selection},
number = {19},
pages = {2507--2517},
pmid = {17720704},
title = {{A review of feature selection techniques in bioinformatics}},
volume = {23},
year = {2007}
}
