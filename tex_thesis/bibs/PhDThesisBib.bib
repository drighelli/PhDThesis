Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Knuth1984a,
author = {Knuth, D. E.},
doi = {10.1093/comjnl/27.2.97},
issn = {0010-4620},
journal = {The Computer Journal},
month = {feb},
number = {2},
pages = {97--111},
publisher = {Oxford University Press},
title = {{Literate Programming}},
url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/27.2.97},
volume = {27},
year = {1984}
}
@inproceedings{russo2015advantages,
author = {Russo, Francesco and Righelli, Dario and Angelini, Claudia},
booktitle = {International Meeting on Computational Intelligence Methods for Bioinformatics and Biostatistics},
organization = {Springer},
pages = {245--258},
title = {{Advantages and Limits in the Adoption of Reproducible Research and R-Tools for the Analysis of Omic Data}},
year = {2015}
}
@article{Rohart2017,
abstract = {The advent of high throughput technologies has led to a wealth of publicly available biological data coming from different sources, the so-called 'omics data (transcriptomics for the study of transcripts, proteomics for proteins, metabolomics for metabolites, etc). Combining such large-scale biological data sets can lead to the discovery of important biological insights, provided that relevant information can be extracted in a holistic manner. Current statistical approaches have been focusing on identifying small subsets of molecules (a 'molecular signature') that explains or predicts biological conditions, but mainly for the analysis of a single data set. In addition, commonly used methods are univariate and consider each biological feature independently. In contrast, linear multivariate methods adopt a system biology approach by statistically integrating several data sets at once and offer an unprecedented opportunity to probe relationships between heterogeneous data sets measured at multiple functional levels. mixOmics is an R package which provides a wide range of linear multivariate methods for data exploration, integration, dimension reduction and visualisation of biological data sets. The methods we have developed extend Projection to Latent Structure (PLS) models for discriminant analysis and data integration and include l1 penalisations to identify molecular signatures. Here we introduce the mixOmics methods specifically developed to integrate large data sets, either at the N-level, where the same individuals are profiled using different 'omics platforms (same N), or at the P-level, where independent studies including different individuals are generated under similar biological conditions using the same 'omics platform (same P). In both cases, the main challenge to face is data heterogeneity, due to inherent platform-specific artefacts (N-integration), or systematic differences arising from experiments assayed at different geographical sites or different times (P-integration). We present and illustrate those novel multivariate methods on existing 'omics data available from the package.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Rohart, Florian and Gautier, Beno{\^{i}}t and Singh, Amrit and {L{\^{e}} Cao}, Kim Anh},
doi = {10.1371/journal.pcbi.1005752},
eprint = {NIHMS150003},
isbn = {1111111111},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {11},
pmid = {29099853},
title = {{mixOmics: An R package for ‘omics feature selection and multiple data integration}},
volume = {13},
year = {2017}
}
@article{Benjamini1995,
abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses-the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferroni-type procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
archivePrefix = {arXiv},
arxivId = {0035-9246/95/57289},
author = {Benjamini, Yoav and Hochberg, Yosef},
doi = {10.2307/2346101},
eprint = {95/57289},
isbn = {1023072346},
issn = {00359246},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
keywords = {BONFERRONI-TYPE PROCEDURES,FAMILYWISE ERROR RATE,MULTIPLE-COMPARISON PROCEDURES,p-VALUES},
pmid = {2346101},
primaryClass = {0035-9246},
title = {{Controlling the false discovery rate: a practical and powerful approach to multiple testing}},
year = {1995}
}
@article{VanBerkum2010,
abstract = {The three-dimensional folding of chromosomes compartmentalizes the genome and and can bring distant functional elements, such as promoters and enhancers, into close spatial proximity (2-6). Deciphering the relationship between chromosome organization and genome activity will aid in understanding genomic processes, like transcription and replication. However, little is known about how chromosomes fold. Microscopy is unable to distinguish large numbers of loci simultaneously or at high resolution. To date, the detection of chromosomal interactions using chromosome conformation capture (3C) and its subsequent adaptations required the choice of a set of target loci, making genome-wide studies impossible (7-10). We developed Hi-C, an extension of 3C that is capable of identifying long range interactions in an unbiased, genome-wide fashion. In Hi-C, cells are fixed with formaldehyde, causing interacting loci to be bound to one another by means of covalent DNA-protein cross-links. When the DNA is subsequently fragmented with a restriction enzyme, these loci remain linked. A biotinylated residue is incorporated as the 5' overhangs are filled in. Next, blunt-end ligation is performed under dilute conditions that favor ligation events between cross-linked DNA fragments. This results in a genome-wide library of ligation products, corresponding to pairs of fragments that were originally in close proximity to each other in the nucleus. Each ligation product is marked with biotin at the site of the junction. The library is sheared, and the junctions are pulled-down with streptavidin beads. The purified junctions can subsequently be analyzed using a high-throughput sequencer, resulting in a catalog of interacting fragments. Direct analysis of the resulting contact matrix reveals numerous features of genomic organization, such as the presence of chromosome territories and the preferential association of small gene-rich chromosomes. Correlation analysis can be applied to the contact matrix, demonstrating that the human genome is segregated into two compartments: a less densely packed compartment containing open, accessible, and active chromatin and a more dense compartment containing closed, inaccessible, and inactive chromatin regions. Finally, ensemble analysis of the contact matrix, coupled with theoretical derivations and computational simulations, revealed that at the megabase scale Hi-C reveals features consistent with a fractal globule conformation.},
author = {van Berkum, Nynke L. and Lieberman-Aiden, Erez and Williams, Louise and Imakaev, Maxim and Gnirke, Andreas and Mirny, Leonid A. and Dekker, Job and Lander, Eric S.},
doi = {10.3791/1869},
isbn = {1940-087X (Electronic)$\backslash$n1940-087X (Linking)},
issn = {1940-087X},
journal = {Journal of Visualized Experiments},
number = {39},
pmid = {20461051},
title = {{Hi-C: A Method to Study the Three-dimensional Architecture of Genomes.}},
url = {http://www.jove.com/index/Details.stp?ID=1869},
year = {2010}
}
@article{Su2017,
abstract = {Su et al. investigated the chromatin accessibility status of neurons in the adult mouse dentate gyrus at different timepoints after activation at the genome-wide level. Their study provides a potential mechanism by which neuronal activity may reshape the epigenetic landscape, thereby dynamically changing transcriptome and neuronal properties over time.},
author = {Su, Yijing and Shin, Jaehoon and Zhong, Chun and Wang, Sabrina and Roychowdhury, Prith and Lim, Jongseuk and Kim, David and Ming, Guo Li and Song, Hongjun},
doi = {10.1038/nn.4494},
isbn = {1097-6256},
issn = {15461726},
journal = {Nature Neuroscience},
pmid = {28166220},
title = {{Neuronal activity modifies the chromatin accessibility landscape in the adult brain}},
year = {2017}
}
@article{Li2011,
abstract = {Motivation: Most existing methods for DNA sequence analysis rely on accurate sequences or genotypes. However, in applications of the next-generation sequencing (NGS), accurate genotypes may not be easily obtained (e.g. multi-sample low-coverage sequencing or somatic mutation discovery). These applications press for the development of new methods for analyzing sequence data with uncertainty. Results: We present a statistical framework for calling SNPs, discovering somatic mutations, inferring population genetical parameters and performing association tests directly based on sequencing data without explicit genotyping or linkage-based imputation. On real data, we demonstrate that our method achieves comparable accuracy to alternative methods for estimating site allele count, for inferring allele frequency spectrum and for association mapping. We also highlight the necessity of using symmetric datasets for finding somatic mutations and confirm that for discovering rare events, mismapping is frequently the leading source of errors. Availability: http://samtools.sourceforge.net. Contact: hengli@broadinstitute.org.},
archivePrefix = {arXiv},
arxivId = {1203.6372},
author = {Li, Heng},
doi = {10.1093/bioinformatics/btr509},
eprint = {1203.6372},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {21},
pages = {2987--2993},
pmid = {21903627},
title = {{A statistical framework for SNP calling, mutation discovery, association mapping and population genetical parameter estimation from sequencing data}},
volume = {27},
year = {2011}
}
@misc{Park2009,
abstract = {Chromatin immunoprecipitation followed by sequencing (ChIP-seq) is a technique for genome-wide profiling of DNA-binding proteins, histone modifications or nucleosomes. Owing to the tremendous progress in next-generation sequencing technology, ChIP-seq offers higher resolution, less noise and greater coverage than its array-based predecessor ChIP-chip. With the decreasing cost of sequencing, ChIP-seq has become an indispensable tool for studying gene regulation and epigenetic mechanisms. In this Review, I describe the benefits and challenges in harnessing this technique with an emphasis on issues related to experimental design and data analysis. ChIP-seq experiments generate large quantities of data, and effective computational analysis will be crucial for uncovering biological mechanisms.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Park, Peter J.},
booktitle = {Nature Reviews Genetics},
doi = {10.1038/nrg2641},
eprint = {NIHMS150003},
isbn = {1471-0064 (Electronic)},
issn = {14710056},
number = {10},
pages = {669--680},
pmid = {19736561},
title = {{ChIP-seq: Advantages and challenges of a maturing technology}},
volume = {10},
year = {2009}
}
@article{Dobin2013,
abstract = {MOTIVATION: Accurate alignment of high-throughput RNA-seq data is a challenging and yet unsolved problem because of the non-contiguous transcript structure, relatively short read lengths and constantly increasing throughput of the sequencing technologies. Currently available RNA-seq aligners suffer from high mapping error rates, low mapping speed, read length limitation and mapping biases.$\backslash$n$\backslash$nRESULTS: To align our large ({\textgreater}80 billon reads) ENCODE Transcriptome RNA-seq dataset, we developed the Spliced Transcripts Alignment to a Reference (STAR) software based on a previously undescribed RNA-seq alignment algorithm that uses sequential maximum mappable seed search in uncompressed suffix arrays followed by seed clustering and stitching procedure. STAR outperforms other aligners by a factor of {\textgreater}50 in mapping speed, aligning to the human genome 550 million 2 × 76 bp paired-end reads per hour on a modest 12-core server, while at the same time improving alignment sensitivity and precision. In addition to unbiased de novo detection of canonical junctions, STAR can discover non-canonical splices and chimeric (fusion) transcripts, and is also capable of mapping full-length RNA sequences. Using Roche 454 sequencing of reverse transcription polymerase chain reaction amplicons, we experimentally validated 1960 novel intergenic splice junctions with an 80-90{\%} success rate, corroborating the high precision of the STAR mapping strategy.$\backslash$n$\backslash$nAVAILABILITY AND IMPLEMENTATION: STAR is implemented as a standalone C++ code. STAR is free open source software distributed under GPLv3 license and can be downloaded from http://code.google.com/p/rna-star/.},
archivePrefix = {arXiv},
arxivId = {1201.0052},
author = {Dobin, Alexander and Davis, Carrie A. and Schlesinger, Felix and Drenkow, Jorg and Zaleski, Chris and Jha, Sonali and Batut, Philippe and Chaisson, Mark and Gingeras, Thomas R.},
doi = {10.1093/bioinformatics/bts635},
eprint = {1201.0052},
isbn = {1367-4811 (Electronic)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
pmid = {23104886},
title = {{STAR: Ultrafast universal RNA-seq aligner}},
year = {2013}
}
@article{Liao2014,
abstract = {Next-generation sequencing technologies generate millions of short sequence reads, which are usually aligned to a reference genome. In many applications, the key information required for downstream analysis is the number of reads mapping to each genomic feature, for example to each exon or each gene. The process of counting reads is called read summarization. Read summarization is required for a great variety of genomic analyses but has so far received relatively little attention in the literature. We present featureCounts, a read summarization program suitable for counting reads generated from either RNA or genomic DNA sequencing experiments. featureCounts implements highly efficient chromosome hashing and feature blocking techniques. It is considerably faster than existing methods (by an order of magnitude for gene-level summarization) and requires far less computer memory. It works with either single or paired-end reads and provides a wide range of options appropriate for different sequencing applications. featureCounts is available under GNU General Public License as part of the Subread (http://subread.sourceforge.net) or Rsubread (http://www.bioconductor.org) software packages.},
archivePrefix = {arXiv},
arxivId = {1305.3347},
author = {Liao, Yang and Smyth, Gordon K. and Shi, Wei},
doi = {10.1093/bioinformatics/btt656},
eprint = {1305.3347},
isbn = {1367-4803},
issn = {14602059},
journal = {Bioinformatics},
pmid = {24227677},
title = {{FeatureCounts: An efficient general purpose program for assigning sequence reads to genomic features}},
year = {2014}
}
@article{Robinson2011,
abstract = {To the Editor:$\backslash$nRapid improvements in sequencing and array-based platforms are resulting in a flood of diverse genome-wide data, including data from exome and whole-genome sequencing, epigenetic surveys, expression profiling of coding and noncoding RNAs, single nucleotide polymorphism (SNP) and copy number profiling, and functional assays. Analysis of these large, diverse data sets holds the promise of a more comprehensive understanding of the genome and its relation to human disease. Experienced and knowledgeable human review is an essential component of this process, complementing computational approaches. This calls for efficient and intuitive visualization tools able to scale to very large data sets and to flexibly integrate multiple data types, including clinical data. However, the sheer volume and scope of data pose a significant challenge to the development of such tools.$\backslash$nView full text},
archivePrefix = {arXiv},
arxivId = {ro},
author = {Robinson, James T and Thorvaldsd{\'{o}}ttir, Helga and Winckler, Wendy and Guttman, Mitchell and Lander, Eric S and Getz, Gad and Mesirov, Jill P},
doi = {10.1038/nbt.1754},
eprint = {ro},
isbn = {1546-1696 (Electronic) 1087-0156 (Linking)},
issn = {10870156},
journal = {Nature Biotechnology},
number = {1},
pages = {24--26},
pmid = {21221095},
title = {{Integrative genomics viewer}},
url = {http://www.nature.com/doifinder/10.1038/nbt.1754},
volume = {29},
year = {2011}
}
@article{Wolstencroft2013,
abstract = {The Taverna workflow tool suite (http://www.taverna.org.uk) is designed to combine distributed Web Services and/or local tools into complex analysis pipelines. These pipelines can be executed on local desktop machines or through larger infrastructure (such as supercomputers, Grids or cloud environments), using the Taverna Server. In bioinformatics, Taverna workflows are typically used in the areas of high-throughput omics analyses (for example, proteomics or transcriptomics), or for evidence gathering methods involving text mining or data mining. Through Taverna, scientists have access to several thousand different tools and resources that are freely available from a large range of life science institutions. Once constructed, the workflows are reusable, executable bioinformatics protocols that can be shared, reused and repurposed. A repository of public workflows is available at http://www.myexperiment.org. This article provides an update to the Taverna tool suite, highlighting new features and developments in the workbench and the Taverna Server.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Wolstencroft, Katherine and Haines, Robert and Fellows, Donal and Williams, Alan and Withers, David and Owen, Stuart and Soiland-Reyes, Stian and Dunlop, Ian and Nenadic, Aleksandra and Fisher, Paul and Bhagat, Jiten and Belhajjame, Khalid and Bacall, Finn and Hardisty, Alex and {Nieva de la Hidalga}, Abraham and {Balcazar Vargas}, Maria P. and Sufi, Shoaib and Goble, Carole},
doi = {10.1093/nar/gkt328},
eprint = {arXiv:1011.1669v3},
isbn = {1362-4962 (Electronic)$\backslash$r0305-1048 (Linking)},
issn = {13624962},
journal = {Nucleic acids research},
number = {Web Server issue},
pmid = {23640334},
title = {{The Taverna workflow suite: designing and executing workflows of Web Services on the desktop, web or in the cloud.}},
volume = {41},
year = {2013}
}
@article{Auerbach2009,
abstract = {Disruptions in local chromatin structure often indicate features of biological interest such as regulatory regions. We find that sonication of cross-linked chromatin, when combined with a size-selection step and massively parallel short-read sequencing, can be used as a method (Sono-Seq) to map locations of high chromatin accessibility in promoter regions. Sono-Seq sites frequently correspond to actively transcribed promoter regions, as evidenced by their co-association with RNA Polymerase II ChIP regions, transcription start sites, histone H3 lysine 4 trimethylation (H3K4me3) marks, and CpG islands; signals over other sites, such as those bound by the CTCF insulator, are also observed. The pattern of breakage by Sono-Seq overlaps with, but is distinct from, that observed for FAIRE and DNase I hypersensitive sites. Our results demonstrate that Sono-Seq can be a useful and simple method by which to map many local alterations in chromatin structure. Furthermore, our results provide insights into the mapping of binding sites by using ChIP–Seq experiments and the value of reference samples that should be used in such experiments.},
author = {Auerbach, R. K. and Euskirchen, G. and Rozowsky, J. and Lamarre-Vincent, N. and Moqtaderi, Z. and Lefrancois, P. and Struhl, K. and Gerstein, M. and Snyder, M.},
doi = {10.1073/pnas.0905443106},
isbn = {1091-6490 (Electronic)$\backslash$n0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
pmid = {19706456},
title = {{Mapping accessible chromatin regions using Sono-Seq}},
year = {2009}
}
@article{Frommer1992,
abstract = {The modulation of DNA-protein interactions by methylation of protein-binding sites in DNA and the occurrence in genomic imprinting, X chromosome inactivation, and fragile X syndrome of different methylation patterns in DNA of different chromosomal origin have underlined the need to establish methylation patterns in individual strands of particular genomic sequences. We report a genomic sequencing method that provides positive identification of 5-methylcytosine residues and yields strand-specific sequences of individual molecules in genomic DNA. The method utilizes bisulfite-induced modification of genomic DNA, under conditions whereby cytosine is converted to uracil, but 5-methylcytosine remains nonreactive. The sequence under investigation is then amplified by PCR with two sets of strand-specific primers to yield a pair of fragments, one from each strand, in which all uracil and thymine residues have been amplified as thymine and only 5-methylcytosine residues have been amplified as cytosine. The PCR products can be sequenced directly to provide a strand-specific average sequence for the population of molecules or can be cloned and sequenced to provide methylation maps of single DNA molecules. We tested the method by defining the methylation status within single DNA strands of two closely spaced CpG dinucleotides in the promoter of the human kininogen gene. During the analysis, we encountered in sperm DNA an unusual methylation pattern, which suggests that the high methylation level of single-copy sequences in sperm may be locally modulated by binding of protein factors in germ-line cells.},
author = {Frommer, M. and McDonald, L. E. and Millar, D. S. and Collis, C. M. and Watt, F. and Grigg, G. W. and Molloy, P. L. and Paul, C. L.},
doi = {10.1073/pnas.89.5.1827},
isbn = {0027-8424 (Print)$\backslash$n0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {5},
pages = {1827--1831},
pmid = {1542678},
title = {{A genomic sequencing protocol that yields a positive display of 5-methylcytosine residues in individual DNA strands.}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.89.5.1827},
volume = {89},
year = {1992}
}
@article{Roberts2011a,
abstract = {The biochemistry of RNA-Seq library preparation results in cDNA fragments that are not uniformly distributed within the transcripts they represent. This non-uniformity must be accounted for when estimating expression levels, and we show how to perform the needed corrections using a likelihood based approach. We find improvements in expression estimates as measured by correlation with independently performed qRT-PCR and show that correction of bias leads to improved replicability of results across libraries and sequencing technologies.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Roberts, Adam and Trapnell, Cole and Donaghey, Julie and Rinn, John L. and Pachter, Lior},
doi = {10.1186/gb-2011-12-3-r22},
eprint = {1111.6189v1},
isbn = {1465-6906},
issn = {14747596},
journal = {Genome Biology},
number = {3},
pmid = {21410973},
title = {{Improving RNA-Seq expression estimates by correcting for fragment bias}},
volume = {12},
year = {2011}
}
@article{Potti2011,
abstract = {Investigations into a case of alleged scientific misconduct have revealed numerous holes in the oversight of science and scientific publishing.},
author = {Potti, Anil and Nevins, Joseph},
issn = {00130613},
journal = {The Economist},
pages = {9--11},
title = {{Misconduct in Science: An array of errors}},
url = {http://www.economist.com/node/21528593},
year = {2011}
}
@article{Iqbal2016,
abstract = {There is a growing movement to encourage reproducibility and transparency practices in the scientific community, including public access to raw data and protocols, the conduct of replication studies, systematic integration of evidence in systematic reviews, and the documentation of funding and potential conflicts of interest. In this survey, we assessed the current status of reproducibility and transparency addressing these indicators in a random sample of 441 biomedical journal articles published in 2000-2014. Only one study provided a full protocol and none made all raw data directly available. Replication studies were rare (n = 4), and only 16 studies had their data included in a subsequent systematic review or meta-analysis. The majority of studies did not mention anything about funding or conflicts of interest. The percentage of articles with no statement of conflict decreased substantially between 2000 and 2014 (94.4{\%} in 2000 to 34.6{\%} in 2014); the percentage of articles reporting statements of conflicts (0{\%} in 2000, 15.4{\%} in 2014) or no conflicts (5.6{\%} in 2000, 50.0{\%} in 2014) increased. Articles published in journals in the clinical medicine category versus other fields were almost twice as likely to not include any information on funding and to have private funding. This study provides baseline data to compare future progress in improving these indicators in the scientific literature.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Iqbal, Shareen A. and Wallach, Joshua D. and Khoury, Muin J. and Schully, Sheri D. and Ioannidis, John P.A.},
doi = {10.1371/journal.pbio.1002333},
eprint = {arXiv:1011.1669v3},
isbn = {1545-7885 (Electronic)$\backslash$r1544-9173 (Linking)},
issn = {15457885},
journal = {PLoS Biology},
number = {1},
pmid = {26726926},
title = {{Reproducible Research Practices and Transparency across the Biomedical Literature}},
volume = {14},
year = {2016}
}
@article{Kanehisa2016,
abstract = {KEGG (http://www.kegg.jp/ or http://www.genome.jp/ kegg/) is an integrated database resource for biolog-ical interpretation of genome sequences and other high-throughput data. Molecular functions of genes and proteins are associated with ortholog groups and stored in the KEGG Orthology (KO) database. The KEGG pathway maps, BRITE hierarchies and KEGG modules are developed as networks of KO nodes, representing high-level functions of the cell and the organism. Currently, more than 4000 com-plete genomes are annotated with KOs in the KEGG GENES database, which can be used as a refer-ence data set for KO assignment and subsequent reconstruction of KEGG pathways and other molec-ular networks. As an annotation resource, the fol-lowing improvements have been made. First, each KO record is re-examined and associated with pro-tein sequence data used in experiments of func-tional characterization. Second, the GENES database now includes viruses, plasmids, and the addendum category for functionally characterized proteins that are not represented in complete genomes. Third, new automatic annotation servers, BlastKOALA and GhostKOALA, are made available utilizing the non-redundant pangenome data set generated from the GENES database. As a resource for translational bioinformatics, various data sets are created for an-timicrobial resistance and drug interaction networks.},
author = {Kanehisa, Minoru and Sato, Yoko and Kawashima, Masayuki and Furumichi, Miho and Tanabe, Mao},
doi = {10.1093/nar/gkv1070},
isbn = {0305-1048},
issn = {13624962},
journal = {Nucleic Acids Research},
pmid = {26476454},
title = {{KEGG as a reference resource for gene and protein annotation}},
year = {2016}
}
@article{Argelaguet2018,
abstract = {Multi-omics studies promise the improved characterization of biological processes across molecular layers. However, methods for the unsupervised integration of the resulting heterogeneous data sets are lacking. We present Multi-Omics Factor Analysis (MOFA), a computational method for discovering the principal sources of variation in multi-omics data sets. MOFA infers a set of (hidden) factors that capture biological and technical sources of variability. It disentangles axes of heterogeneity that are shared across multiple modalities and those specific to individual data modalities. The learnt factors enable a variety of downstream analyses, including identification of sample subgroups, data imputation and the detection of outlier samples. We applied MOFA to a cohort of 200 patient samples of chronic lymphocytic leukaemia, profiled for somatic mutations, RNA expression, DNA methylation and ex vivo drug responses. MOFA identified major dimensions of disease heterogeneity, including immunoglobulin heavy-chain variable region status, trisomy of chromosome 12 and previously underappreciated drivers, such as response to oxidative stress. In a second application, we used MOFA to analyse single-cell multi-omics data, identifying coordinated transcriptional and epigenetic changes along cell differentiation.},
archivePrefix = {arXiv},
arxivId = {217554},
author = {Argelaguet, Ricard and Velten, Britta and Arnol, Damien and Dietrich, Sascha and Zenz, Thorsten and Marioni, John C and Buettner, Florian and Huber, Wolfgang and Stegle, Oliver},
doi = {10.15252/msb.20178124},
eprint = {217554},
issn = {1744-4292},
journal = {Molecular Systems Biology},
number = {6},
pages = {e8124},
pmid = {29925568},
title = {{Multi‐Omics Factor Analysis—a framework for unsupervised integration of multi‐omics data sets}},
url = {http://msb.embopress.org/lookup/doi/10.15252/msb.20178124},
volume = {14},
year = {2018}
}
@article{Barrett2013,
abstract = {The Gene Expression Omnibus (GEO, http://www.ncbi.nlm.nih.gov/geo/) is an international public repository for high-throughput microarray and next-generation sequence functional genomic data sets submitted by the research community. The resource supports archiving of raw data, processed data and metadata which are indexed, cross-linked and searchable. All data are freely available for download in a variety of formats. GEO also provides several web-based tools and strategies to assist users to query, analyse and visualize data. This article reports current status and recent database developments, including the release of GEO2R, an R-based web application that helps users analyse GEO data.},
author = {Barrett, Tanya and Wilhite, Stephen E. and Ledoux, Pierre and Evangelista, Carlos and Kim, Irene F. and Tomashevsky, Maxim and Marshall, Kimberly A. and Phillippy, Katherine H. and Sherman, Patti M. and Holko, Michelle and Yefanov, Andrey and Lee, Hyeseung and Zhang, Naigong and Robertson, Cynthia L. and Serova, Nadezhda and Davis, Sean and Soboleva, Alexandra},
doi = {10.1093/nar/gks1193},
isbn = {1362-4962 (Electronic)$\backslash$r0305-1048 (Linking)},
issn = {03051048},
journal = {Nucleic Acids Research},
pmid = {23193258},
title = {{NCBI GEO: Archive for functional genomics data sets - Update}},
year = {2013}
}
@article{Roberts2011,
abstract = {We describe a new 'reference annotation based transcript assembly' problem for RNA-Seq data that involves assembling novel transcripts in the context of an existing annotation. This problem arises in the analysis of expression in model organisms, where it is desirable to leverage existing annotations for discovering novel transcripts. We present an algorithm for reference annotation-based transcript assembly and show how it can be used to rapidly investigate novel transcripts revealed by RNA-Seq in comparison with a reference annotation.},
archivePrefix = {arXiv},
arxivId = {171},
author = {Roberts, Adam and Pimentel, Harold and Trapnell, Cole and Pachter, Lior},
doi = {10.1093/bioinformatics/btr355},
eprint = {171},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {17},
pages = {2325--2329},
pmid = {21697122},
title = {{Identification of novel transcripts in annotated genomes using RNA-seq}},
volume = {27},
year = {2011}
}
@inproceedings{Sha2015,
abstract = {We compare methods for filtering RNA-seq lowexpression genes and investigate the effect of filtering on detection of differentially expressed genes (DEGs). Although RNA-seq technology has improved the dynamic range of gene expression quantification, low-expression genes may be indistinguishable from sampling noise. The presence of noisy, low-expression genes can decrease the sensitivity of detecting DEGs. Thus, identification and filtering of these low-expression genes may improve DEG detection sensitivity. Using the SEQC benchmark dataset, we investigate the effect of different filtering methods on DEG detection sensitivity. Moreover, we investigate the effect of RNA-seq pipelines on optimal filtering thresholds. Results indicate that the filtering threshold that maximizes the total number of DEGs closely corresponds to the threshold that maximizes DEG detection sensitivity. Transcriptome reference annotation, expression quantification method, and DEG detection method are statistically significant RNA-seq pipeline factors that affect the optimal filtering threshold.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Sha, Ying and Phan, John H. and Wang, May D.},
booktitle = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
doi = {10.1109/EMBC.2015.7319872},
eprint = {15334406},
isbn = {9781424492718},
issn = {1557170X},
pmid = {26737772},
title = {{Effect of low-expression gene filtering on detection of differentially expressed genes in RNA-seq data}},
year = {2015}
}
@article{Reimand2016,
abstract = {Functional enrichment analysis is a key step in interpreting gene lists discovered in diverse high-throughput experiments. g:Profiler studies flat and ranked gene lists and finds statistically significant Gene Ontology terms, pathways and other gene function related terms. Translation of hundreds of gene identifiers is another core feature of g:Profiler. Since its first publication in 2007, our web server has become a popular tool of choice among basic and translational researchers. Timeliness is a major advantage of g:Profiler as genome and pathway information is synchronized with the Ensembl database in quarterly updates. g:Profiler supports 213 species including mammals and other vertebrates, plants, insects and fungi. The 2016 update of g:Profiler introduces several novel features. We have added further functional datasets to interpret gene lists, including transcription factor binding site predictions, Mendelian disease annotations, information about protein expression and complexes and gene mappings of human genetic polymorphisms. Besides the interactive web interface, g:Profiler can be accessed in computational pipelines using our R package, Python interface and BioJS component. g:Profiler is freely available at http://biit.cs.ut.ee/gprofiler/. },
author = {Reimand, J{\"{u}}ri and Arak, Tambet and Adler, Priit and Kolberg, Liis and Reisberg, Sulev and Peterson, Hedi and Vilo, Jaak},
doi = {10.1093/nar/gkw199},
isbn = {13624962 (Electronic)},
issn = {13624962},
journal = {Nucleic acids research},
number = {W1},
pages = {W83--W89},
pmid = {27098042},
title = {{g:Profiler-a web server for functional interpretation of gene lists (2016 update)}},
volume = {44},
year = {2016}
}
@article{Nueda2014,
abstract = {MOTIVATION The widespread adoption of RNA-seq to quantitatively measure gene expression has increased the scope of sequencing experimental designs to include time-course experiments. maSigPro is an R package specifically suited for the analysis of time-course gene expression data, which was developed originally for microarrays and hence was limited in its application to count data. RESULTS We have updated maSigPro to support RNA-seq time series analysis by introducing generalized linear models in the algorithm to support the modeling of count data while maintaining the traditional functionalities of the package. We show a good performance of the maSigPro-GLM method in several simulated time-course scenarios and in a real experimental dataset. AVAILABILITY AND IMPLEMENTATION The package is freely available under the LGPL license from the Bioconductor Web site (http://bioconductor.org).},
author = {Nueda, Mar{\'{i}}a Jos{\'{e}} and Tarazona, Sonia and Conesa, Ana},
doi = {10.1093/bioinformatics/btu333},
isbn = {1367-4803},
issn = {14602059},
journal = {Bioinformatics},
pmid = {24894503},
title = {{Next maSigPro: Updating maSigPro bioconductor package for RNA-seq time series}},
year = {2014}
}
@misc{Costa2013,
abstract = {The availability of the human genome sequence has allowed identification of disease-causing mutations in many Mendelian disorders, and detection of significant associations of nucleotide polymorphisms to complex diseases and traits. Despite these progresses, finding the causative variations for most of the common diseases remains a complex task. Several studies have shown gene expression analyses provide a quite unbiased way to investigate complex traits and common disorders' pathogenesis. Therefore, whole-transcriptome analysis is increasingly acquiring a key role in the knowledge of mechanisms responsible for complex diseases. Hybridization-and tag-based technologies have elucidated the involvement of multiple genes and pathways in pathological conditions, providing insights into the expression of thousand of coding and noncoding RNAs, such as microRNAs. However, the introduction of Next-Generation Sequencing, particularly of RNA-Seq, has overcome some drawbacks of previously used technologies. Identifying, in a single experiment, potentially novel genes/exons and splice isoforms, RNA editing, fusion transcripts and allele-specific expression are some of its advantages. RNA-Seq has been fruitfully applied to study cancer and host-pathogens interactions, and it is taking first steps for studying neurodegenerative diseases (ND) as well as neuropsychiatric diseases. In addition, it is emerging as a very powerful tool to study quantitative trait loci associated with gene expression in complex diseases. This paper provides an overview on gene expression profiling of complex diseases, with emphasis on RNA-Seq, its advantages over conventional technologies for studying cancer and ND, and for linking nucleotide variations to gene expression changes, also discussing its limitations.},
author = {Costa, Valerio and Aprile, Marianna and Esposito, Roberta and Ciccodicola, Alfredo},
booktitle = {European Journal of Human Genetics},
doi = {10.1038/ejhg.2012.129},
isbn = {1476-5438 (Electronic)$\backslash$n1018-4813 (Linking)},
issn = {10184813},
keywords = {RNA-Seq,epigenetics,noncoding RNA},
number = {2},
pages = {134--142},
pmid = {22739340},
title = {{RNA-Seq and human complex diseases: Recent accomplishments and future perspectives}},
volume = {21},
year = {2013}
}
@misc{Carlson2018,
author = {Carlson, Marc},
doi = {https://doi.org/doi:10.18129/B9.bioc.org.Mm.eg.db},
title = {{org.Mm.eg.db: Genome wide annotation for Mouse.}},
year = {2018}
}
@article{McCarthy2012,
abstract = {A flexible statistical framework is developed for the analysis of read counts from RNA-Seq gene expression studies. It provides the ability to analyse complex experiments involving multiple treatment conditions and blocking variables while still taking full account of biological variation. Biological variation between RNA samples is estimated separately from the technical variation associated with sequencing technologies. Novel empirical Bayes methods allow each gene to have its own specific variability, even when there are relatively few biological replicates from which to estimate such variability. The pipeline is implemented in the edgeR package of the Bioconductor project. A case study analysis of carcinoma data demonstrates the ability of generalized linear model methods (GLMs) to detect differential expression in a paired design, and even to detect tumour-specific expression changes. The case study demonstrates the need to allow for gene-specific variability, rather than assuming a common dispersion across genes or a fixed relationship between abundance and variability. Genewise dispersions de-prioritize genes with inconsistent results and allow the main analysis to focus on changes that are consistent between biological replicates. Parallel computational approaches are developed to make non-linear model fitting faster and more reliable, making the application of GLMs to genomic data more convenient and practical. Simulations demonstrate the ability of adjusted profile likelihood estimators to return accurate estimators of biological variability in complex situations. When variation is gene-specific, empirical Bayes estimators provide an advantageous compromise between the extremes of assuming common dispersion or separate genewise dispersion. The methods developed here can also be applied to count data arising from DNA-Seq applications, including ChIP-Seq for epigenetic marks and DNA methylation analyses.},
author = {McCarthy, Davis J. and Chen, Yunshun and Smyth, Gordon K.},
doi = {10.1093/nar/gks042},
isbn = {1362-4962 (Electronic)$\backslash$r0305-1048 (Linking)},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {10},
pages = {4288--4297},
pmid = {22287627},
title = {{Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation}},
volume = {40},
year = {2012}
}
@article{Andrews2010,
abstract = {FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis. The main functions of FastQC are Import of data from BAM, SAM or FastQ files (any variant) Providing a quick overview to tell you in which areas there may be problems Summary graphs and tables to quickly assess your data Export of results to an HTML based permanent report Offline operation to allow automated generation of reports without running the interactive application},
author = {Andrews, Simon},
doi = {citeulike-article-id:11583827},
isbn = {0022-5347},
issn = {00029548 (ISSN)},
journal = {Babraham Bioinformatics},
pages = {http://www.bioinformatics.babraham.ac.uk/projects/},
pmid = {16406909},
title = {{FastQC}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:FastQC+a+quality+control+tool+for+high+throughput+sequence+data.{\#}0},
year = {2010}
}
@article{Trapnell2010,
abstract = {High-throughput mRNA sequencing (RNA-Seq) promises simultaneous transcript discovery and abundance estimation. However, this would require algorithms that are not restricted by prior gene annotations and that account for alternative transcription and splicing. Here we introduce such algorithms in an open-source software program called Cufflinks. To test Cufflinks, we sequenced and analyzed {\textgreater}430 million paired 75-bp RNA-Seq reads from a mouse myoblast cell line over a differentiation time series. We detected 13,692 known transcripts and 3,724 previously unannotated ones, 62{\%} of which are supported by independent expression data or by homologous genes in other species. Over the time series, 330 genes showed complete switches in the dominant transcription start site (TSS) or splice isoform, and we observed more subtle shifts in 1,304 other genes. These results suggest that Cufflinks can illuminate the substantial regulatory flexibility and complexity in even this well-studied model of muscle development and that it can improve transcriptome-based genome annotation.},
archivePrefix = {arXiv},
arxivId = {171},
author = {Trapnell, Cole and Williams, Brian A. and Pertea, Geo and Mortazavi, Ali and Kwan, Gordon and {Van Baren}, Marijke J. and Salzberg, Steven L. and Wold, Barbara J. and Pachter, Lior},
doi = {10.1038/nbt.1621},
eprint = {171},
isbn = {1546-1696 (Electronic)$\backslash$r1087-0156 (Linking)},
issn = {10870156},
journal = {Nature Biotechnology},
number = {5},
pages = {511--515},
pmid = {20436464},
title = {{Transcript assembly and quantification by RNA-Seq reveals unannotated transcripts and isoform switching during cell differentiation}},
volume = {28},
year = {2010}
}
@article{Ou2018,
abstract = {ATAC-seq (Assays for Transposase-Accessible Chromatin using sequencing) is a recently developed technique for genome-wide analysis of chromatin accessibility. Compared to earlier methods for assaying chromatin accessibility, ATAC-seq is faster and easier to perform, does not require cross-linking, has higher signal to noise ratio, and can be performed on small cell numbers. However, to ensure a successful ATAC-seq experiment, step-by-step quality assurance processes, including both wet lab quality control and in silico quality assessment, are essential. While several tools have been developed or adopted for assessing read quality, identifying nucleosome occupancy and accessible regions from ATAC-seq data, none of the tools provide a comprehensive set of functionalities for preprocessing and quality assessment of aligned ATAC-seq datasets. We have developed a Bioconductor package, ATACseqQC, for easily generating various diagnostic plots to help researchers quickly assess the quality of their ATAC-seq data. In addition, this package contains functions to preprocess aligned ATAC-seq data for subsequent peak calling. Here we demonstrate the utilities of our package using 25 publicly available ATAC-seq datasets from four studies. We also provide guidelines on what the diagnostic plots should look like for an ideal ATAC-seq dataset. This software package has been used successfully for preprocessing and assessing several in-house and public ATAC-seq datasets. Diagnostic plots generated by this package will facilitate the quality assessment of ATAC-seq data, and help researchers to evaluate their own ATAC-seq experiments as well as select high-quality ATAC-seq datasets from public repositories such as GEO to avoid generating hypotheses or drawing conclusions from low-quality ATAC-seq experiments. The software, source code, and documentation are freely available as a Bioconductor package at 
                    https://bioconductor.org/packages/release/bioc/html/ATACseqQC.html
                    
                  .},
archivePrefix = {arXiv},
arxivId = {arXiv:1311.3268v1},
author = {Ou, Jianhong and Liu, Haibo and Yu, Jun and Kelliher, Michelle A. and Castilla, Lucio H. and Lawson, Nathan D. and Zhu, Lihua Julie},
doi = {10.1186/s12864-018-4559-3},
eprint = {arXiv:1311.3268v1},
issn = {14712164},
journal = {BMC Genomics},
keywords = {ATAC-seq,ATACseqQC,Chromatin accessibility,Quality control},
number = {1},
pmid = {29490630},
title = {{ATACseqQC: A Bioconductor package for post-alignment quality assessment of ATAC-seq data}},
volume = {19},
year = {2018}
}
@misc{Pedersen,
author = {Pedersen, Thomas Lin},
title = {{shinyFiles}},
year = {2018}
}
@article{Sales2012a,
abstract = {BACKGROUND: Gene set analysis is moving towards considering pathway topology as a crucial feature. Pathway elements are complex entities such as protein complexes, gene family members and chemical compounds. The conversion of pathway topology to a gene/protein networks (where nodes are a simple element like a gene/protein) is a critical and challenging task that enables topology-based gene set analyses.Unfortunately, currently available R/Bioconductor packages provide pathway networks only from single databases. They do not propagate signals through chemical compounds and do not differentiate between complexes and gene families.RESULTS: Here we present graphite, a Bioconductor package addressing these issues. Pathway information from four different databases is interpreted following specific biologically-driven rules that allow the reconstruction of gene-gene networks taking into account protein complexes, gene families and sensibly removing chemical compounds from the final graphs. The resulting networks represent a uniform resource for pathway analyses. Indeed, graphite provides easy access to three recently proposed topological methods. The graphite package is available as part of the Bioconductor software suite.CONCLUSIONS: graphite is an innovative package able to gather and make easily available the contents of the four major pathway databases. In the field of topological analysis graphite acts as a provider of biological information by reducing the pathway complexity considering the biological meaning of the pathway elements},
author = {Sales, Gabriele and Calura, Enrica and Cavalieri, Duccio and Romualdi, Chiara},
doi = {10.1186/1471-2105-13-20},
isbn = {1471-2105},
issn = {14712105},
journal = {BMC Bioinformatics},
number = {1},
pmid = {22292714},
title = {{Graphite - a Bioconductor package to convert pathway topology to gene network}},
volume = {13},
year = {2012}
}
@article{Dillies2013d,
author = {Dillies, M.-A. and Rau, A. and Aubert, J. and Hennequet-Antier, C. and Jeanmougin, M. and Servant, N. and Keime, C. and Marot, G. and Castel, D. and Estelle, J. and Guernec, G. and Jagla, B. and Jouneau, L. and Laloe, D. and {Le Gall}, C. and Schaeffer, B. and {Le Crom}, S. and Guedj, M. and Jaffrezic, F.},
doi = {10.1093/bib/bbs046},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Dillies et al. - 2013 - A comprehensive evaluation of normalization methods for Illumina high-throughput RNA sequencing data analysis(2).pdf:pdf},
issn = {1467-5463},
journal = {Briefings in Bioinformatics},
keywords = {differential analysis,high-throughput sequencing,letto,next generation sequencing,ngs,normalization,rna-seq,stampato},
mendeley-tags = {letto,next generation sequencing,ngs,normalization,rna-seq,stampato},
number = {6},
pages = {671--683},
title = {{A comprehensive evaluation of normalization methods for Illumina high-throughput RNA sequencing data analysis}},
url = {http://bib.oxfordjournals.org/cgi/doi/10.1093/bib/bbs046},
volume = {14},
year = {2013}
}
@article{Angelini2014c,
author = {Angelini, Claudia and Costa, Valerio},
doi = {10.3389/fcell.2014.00051},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Angelini, Costa - 2014 - Understanding gene regulatory mechanisms by integrating ChIP-seq and RNA-seq data statistical solutions to biol.pdf:pdf},
issn = {2296-634X},
journal = {Frontiers in Cell and Developmental Biology},
keywords = {ChIP-seq, data integration, gene regulatory mechan,Integration,chip-seq,data integration,gene regulatory mechanisms,next generation sequencing,ngs,rna-seq,statistics},
mendeley-tags = {Integration,next generation sequencing,ngs},
number = {September},
pages = {1--8},
title = {{Understanding gene regulatory mechanisms by integrating ChIP-seq and RNA-seq data: statistical solutions to biological problems}},
url = {http://journal.frontiersin.org/article/10.3389/fcell.2014.00051/abstract},
volume = {2},
year = {2014}
}
@article{Goecks2010,
abstract = {Increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. Galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. Galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. Galaxy Pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Goecks, Jeremy and Nekrutenko, Anton and Taylor, James and Afgan, Enis and Ananda, Guruprasad and Baker, Dannon and Blankenberg, Dan and Chakrabarty, Ramkrishna and Coraor, Nate and Goecks, Jeremy and {Von Kuster}, Greg and Lazarus, Ross and Li, Kanwei and Taylor, James and Vincent, Kelly},
doi = {10.1186/gb-2010-11-8-r86},
eprint = {arXiv:1011.1669v3},
isbn = {1465-6914 (Electronic)$\backslash$r1465-6906 (Linking)},
issn = {1474760X},
journal = {Genome Biology},
number = {8},
pmid = {20738864},
title = {{Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences}},
volume = {11},
year = {2010}
}
@article{RussoRighelli2016,
abstract = {We present the advancements and novelties recently introduced in RNASeqGUI, a graphical user interface that helps biologists to handle and analyse large data collected in RNA-Seq experiments. This work focuses on the concept of reproducible research and shows how it has been incorporated in RNASeqGUI to provide reproducible (computational) results. The novel version of RNASeqGUI combines graphical interfaces with tools for reproducible research, such as literate statistical programming, human readable report, parallel executions, caching, and interactive and web-explorable tables of results. These features allow the user to analyse big datasets in a fast, efficient, and reproducible way. Moreover, this paper represents a proof of concept, showing a simple way to develop computational tools for Life Science in the spirit of reproducible research.},
author = {Russo, Francesco and Righelli, Dario and Angelini, Claudia},
doi = {10.1155/2016/7972351},
issn = {23146141},
journal = {BioMed Research International},
pmid = {26977414},
title = {{Advancements in RNASeqGUI towards a Reproducible Analysis of RNA-Seq Experiments}},
volume = {2016},
year = {2016}
}
@article{Winter2013,
abstract = {DNase-seq is primarily used to identify nucleosome-depleted DNase I hypersensitive (DHS) sites genome-wide that correspond to active regulatory elements. However, ≈ 40 yr ago it was demonstrated that DNase I also digests with a ≈ 10-bp periodicity around nucleosomes matching the exposure of the DNA minor groove as it wraps around histones. Here, we use DNase-seq data from 49 samples representing diverse cell types to reveal this digestion pattern at individual loci and predict genomic locations where nucleosome rotational positioning, the orientation of DNA with respect to the histone surface, is stably maintained. We call these regions DNase I annotated regions of nucleosome stability (DARNS). Compared to MNase-seq experiments, we show DARNS correspond well to annotated nucleosomes. Interestingly, many DARNS are positioned over only one side of annotated nucleosomes, suggesting that the periodic digestion pattern attenuates over the nucleosome dyad. DARNS reproduce the arrangement of nucleosomes around transcription start sites and are depleted at ubiquitous DHS sites. We also generated DARNS from multiple lymphoblast cell line (LCL) samples. We found that LCL DARNS were enriched at DHS sites present in most of the original 49 samples but absent in LCLs, while multi-cell-type DARNS were enriched at LCL-specific DHS sites. This indicates that variably open DHS sites are often occupied by rotationally stable nucleosomes in cell types where the DHS site is closed. DARNS provide additional information about precise DNA orientation within individual nucleosomes not available from other nucleosome positioning assays and contribute to understanding the role of chromatin in gene regulation.},
author = {Winter, Deborah R. and Song, Lingyun and Mukherjee, Sayan and Furey, Terrence S. and Crawford, Gregory E.},
doi = {10.1101/gr.150482.112},
isbn = {1549-5469 (Electronic)$\backslash$r1088-9051 (Linking)},
issn = {10889051},
journal = {Genome Research},
number = {7},
pages = {1118--1129},
pmid = {23657885},
title = {{DNase-seq predicts regions of rotational nucleosome stability across diverse human cell types}},
volume = {23},
year = {2013}
}
@misc{Poplawski2016,
abstract = {RNA-sequencing (RNA-seq) has become an established way for measuring gene expression in model organisms and humans. While methods development for refining the corresponding data processing and analysis pipeline is ongoing, protocols for typical steps have been proposed and are widely used. Several user interfaces have been developed for making such analysis steps accessible to life scientists without extensive knowledge of command line tools. We performed a systematic search and evaluation of such interfaces to investigate to what extent these can indeed facilitate RNA-seq data analysis. We found a total of 29 open source interfaces, and six of the more widely used interfaces were evaluated in detail. Central criteria for evaluation were ease of configuration, documentation, usability, computational demand and reporting. No interface scored best in all of these criteria, indicating that the final choice will depend on the specific perspective of users and the corresponding weighting of criteria. Considerable technical hurdles had to be overcome in our evaluation. For many users, this will diminish potential benefits compared with command line tools, leaving room for future improvement of interfaces.},
author = {Poplawski, Alicia and Marini, Federico and Hess, Moritz and Zeller, Tanja and Mazur, Johanna and Binder, Harald},
booktitle = {Briefings in Bioinformatics},
doi = {10.1093/bib/bbv036},
isbn = {1477-4054 (Electronic)$\backslash$r1467-5463 (Linking)},
issn = {14774054},
keywords = {Evaluation,Interface,RNA-seq,Systematic search,Workflow},
number = {2},
pages = {213--223},
pmid = {26108229},
title = {{Systematically evaluating interfaces for RNA-seq analysis from a life scientist perspective}},
volume = {17},
year = {2016}
}
@article{Yu2015,
abstract = {UNLABELLED ChIPseeker is an R package for annotating ChIP-seq data analysis. It supports annotating ChIP peaks and provides functions to visualize ChIP peaks coverage over chromosomes and profiles of peaks binding to TSS regions. Comparison of ChIP peak profiles and annotation are also supported. Moreover, it supports evaluating significant overlap among ChIP-seq datasets. Currently, ChIPseeker contains 15 000 bed file information from GEO database. These datasets can be downloaded and compare with user's own data to explore significant overlap datasets for inferring co-regulation or transcription factor complex for further investigation. AVAILABILITY AND IMPLEMENTATION ChIPseeker is released under Artistic-2.0 License. The source code and documents are freely available through Bioconductor (http://www.bioconductor.org/packages/release/bioc/html/ChIPseeker.html).},
author = {Yu, Guangchuang and Wang, Li Gen and He, Qing Yu},
doi = {10.1093/bioinformatics/btv145},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {14602059},
journal = {Bioinformatics},
number = {14},
pages = {2382--2383},
pmid = {25765347},
title = {{ChIP seeker: An R/Bioconductor package for ChIP peak annotation, comparison and visualization}},
volume = {31},
year = {2015}
}
@incollection{Kluyver2016,
abstract = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.},
author = {{Thomas Kluyver, Benjamin Ragan-Kelley, Fernando P{\'{e}}rez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, Jessica Hamrick, Jason Grout, Sylvain Corlay, Paul Ivanov, Dami{\'{a}}n Avila, Safia Abdalla, Carol Willing}, Jupyter Development Team},
booktitle = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
doi = {10.3233/978-1-61499-649-1-87},
isbn = {9781614996491},
issn = {0015-0193},
pages = {87 -- 90},
pmid = {23502158},
title = {{Jupyter Notebooks – a publishing format for reproducible computational workflows}},
url = {http://ebooks.iospress.nl/publication/42900},
year = {2016}
}
@article{Lawrence2013,
author = {Lawrence, Michael and Huber, Wolfgang and Pag{\`{e}}s, Herv{\'{e}} and Aboyoun, Patrick and Carlson, Marc and Gentleman, Robert and Morgan, Martin T. and Carey, Vincent J.},
doi = {10.1371/journal.pcbi.1003118},
editor = {Prlic, Andreas},
issn = {1553-7358},
journal = {PLoS Computational Biology},
month = {aug},
number = {8},
pages = {e1003118},
title = {{Software for Computing and Annotating Genomic Ranges}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1003118},
volume = {9},
year = {2013}
}
@article{Yeh2018,
abstract = {STUDY DESIGN: Propensity score-matched, retrospective cohort study. OBJECTIVES: To determine the risk of developing Alzheimer's disease (AD) in patients with spinal cord injury (SCI). SETTING: The present study used Taiwan's National Health Insurance Research Database. METHODS: A total of 9257 patients who had 2 ambulatory visits with a diagnosis of SCI in 2001 were included in the SCI group. The non-SCI group consisted of 37,028 propensity score-matched patients without a diagnosis of SCI. The cumulative incidence of AD was estimated for each of the two patient groups using the Kaplan-Meier method. Stratified Cox proportional hazard regression was then employed to assess the influence of SCI on the risk of AD. RESULTS: During the follow-up period, 25 subjects in the SCI group and 57 in the non-SCI group developed AD. The cumulative incidence of AD in the SCI group was higher than in the non-SCI group (P = 0.0168); and the hazard ratio of AD for the SCI group, as compared to the non-SCI group, was 1.71 (95{\%} CI 1.06-2.76, P = 0.0273). CONCLUSIONS: This study suggests that patients with SCI have an increased risk of developing AD.},
author = {Yeh, Tian Shin and Ho, Yu Chun and Hsu, Cherng Lan and Pan, Shin Liang},
doi = {10.1038/s41393-017-0009-3},
isbn = {1476-5624 (Electronic) 1362-4393 (Linking)},
issn = {14765624},
journal = {Spinal Cord},
number = {2},
pages = {151--157},
pmid = {29057990},
title = {{Spinal cord injury and Alzheimer's disease risk: A population-based, retrospective cohort study article}},
volume = {56},
year = {2018}
}
@article{Soneson2013d,
abstract = {BACKGROUND: Finding genes that are differentially expressed between conditions is an integral part of understanding the molecular basis of phenotypic variation. In the past decades, DNA microarrays have been used extensively to quantify the abundance of mRNA corresponding to different genes, and more recently high-throughput sequencing of cDNA (RNA-seq) has emerged as a powerful competitor. As the cost of sequencing decreases, it is conceivable that the use of RNA-seq for differential expression analysis will increase rapidly. To exploit the possibilities and address the challenges posed by this relatively new type of data, a number of software packages have been developed especially for differential expression analysis of RNA-seq data.$\backslash$n$\backslash$nRESULTS: We conducted an extensive comparison of eleven methods for differential expression analysis of RNA-seq data. All methods are freely available within the R framework and take as input a matrix of counts, i.e. the number of reads mapping to each genomic feature of interest in each of a number of samples. We evaluate the methods based on both simulated data and real RNA-seq data.$\backslash$n$\backslash$nCONCLUSIONS: Very small sample sizes, which are still common in RNA-seq experiments, impose problems for all evaluated methods and any results obtained under such conditions should be interpreted with caution. For larger sample sizes, the methods combining a variance-stabilizing transformation with the 'limma' method for differential expression analysis perform well under many different conditions, as does the nonparametric SAMseq method.},
author = {Soneson, Charlotte and Delorenzi, Mauro},
doi = {10.1186/1471-2105-14-91},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Soneson, Delorenzi - 2013 - A comparison of methods for differential expression analysis of RNA-seq data.pdf:pdf},
isbn = {10.1186/1471-2105-14-91},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Animals,DNA, Complementary,DNA, Complementary: genetics,Gene Expression Profiling,Gene Expression Profiling: methods,Genome,Genomics,Genomics: methods,Mice,Mice, Inbred C57BL,Mice, Inbred DBA,RNA, Messenger,RNA, Messenger: metabolism,Sequence Analysis, RNA,Software,differential expression,next generation sequencing,ngs,rna-seq},
mendeley-tags = {differential expression,next generation sequencing,ngs,rna-seq},
number = {1},
pages = {91},
pmid = {23497356},
publisher = {BMC Bioinformatics},
title = {{A comparison of methods for differential expression analysis of RNA-seq data.}},
url = {http://www.biomedcentral.com/1471-2105/14/91},
volume = {14},
year = {2013}
}
@misc{Costa2010,
abstract = {{\textless}p{\textgreater}In recent years, the introduction of massively parallel sequencing platforms for Next Generation Sequencing (NGS) protocols, able to simultaneously sequence hundred thousand DNA fragments, dramatically changed the landscape of the genetics studies. RNA-Seq for transcriptome studies, Chip-Seq for DNA-proteins interaction, CNV-Seq for large genome nucleotide variations are only some of the intriguing new applications supported by these innovative platforms. Among them RNA-Seq is perhaps the most complex NGS application. Expression levels of specific genes, differential splicing, allele-specific expression of transcripts can be accurately determined by RNA-Seq experiments to address many biological-related issues. All these attributes are not readily achievable from previously widespread hybridization-based or tag sequence-based approaches. However, the unprecedented level of sensitivity and the large amount of available data produced by NGS platforms provide clear advantages as well as new challenges and issues. This technology brings the great power to make several new biological observations and discoveries, it also requires a considerable effort in the development of new bioinformatics tools to deal with these massive data files. The paper aims to give a survey of the RNA-Seq methodology, particularly focusing on the challenges that this application presents both from a biological and a bioinformatics point of view.{\textless}/p{\textgreater}},
author = {Costa, Valerio and Angelini, Claudia and {De Feis}, Italia and Ciccodicola, Alfredo},
booktitle = {Journal of Biomedicine and Biotechnology},
doi = {10.1155/2010/853916},
isbn = {1110-7251 (Electronic)$\backslash$r1110-7243 (Linking)},
issn = {11107243},
pmid = {20625424},
title = {{Uncovering the complexity of transcriptomes with RNA-Seq}},
volume = {2010},
year = {2010}
}
@misc{Oshlack2010,
abstract = {Many methods and tools are available for preprocessing high-throughput RNA sequencing data and detecting differential expression.},
author = {Oshlack, Alicia and Robinson, Mark D. and Young, Matthew D.},
booktitle = {Genome Biology},
doi = {10.1186/gb-2010-11-12-220},
isbn = {1465-6906},
issn = {14747596},
number = {12},
pmid = {21176179},
title = {{From RNA-seq reads to differential expression results}},
volume = {11},
year = {2010}
}
@article{Goecks2010a,
abstract = {Increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. Galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. Galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. Galaxy Pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Goecks, Jeremy and Nekrutenko, Anton and Taylor, James and Afgan, Enis and Ananda, Guruprasad and Baker, Dannon and Blankenberg, Dan and Chakrabarty, Ramkrishna and Coraor, Nate and Goecks, Jeremy and {Von Kuster}, Greg and Lazarus, Ross and Li, Kanwei and Taylor, James and Vincent, Kelly},
doi = {10.1186/gb-2010-11-8-r86},
eprint = {arXiv:1011.1669v3},
isbn = {1465-6914 (Electronic)$\backslash$r1465-6906 (Linking)},
issn = {1474760X},
journal = {Genome Biology},
number = {8},
pmid = {20738864},
title = {{Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences}},
volume = {11},
year = {2010}
}
@article{Xie2012,
abstract = {The original paradigm of literate programming was brought forward mainly for software development, or specifically, to mix source code (for computer) and documentation (for human) together. Early systems include WEB and Noweb; Sweave (Leisch, 2002) was derived from the latter, but it is less focused on documenting software, instead it is mainly used for reproducible data analysis and generating statistical reports. The knitr package (Xie, 2012) is following the steps of Sweave. For this manual, I assume readers have some background knowledge of Sweave to understand the technical details; for a reference of available options, hooks and demos, see the package homepage http://yihui.github.com/knitr/.},
author = {Xie, Yihui},
doi = {http://yihui.name/knitr/},
issn = {1687-1472},
journal = {R package version},
pmid = {16224684},
title = {{knitr: A General-Purpose Tool for Dynamic Report Generation in R}},
year = {2012}
}
@article{Yeh2016,
abstract = {Spinal cord injury and Parkinson's disease: a population-based, propensity score-matched, longitudinal follow-up study},
author = {Yeh, T. S. and Huang, Y. P. and Wang, H. I. and Pan, S. L.},
doi = {10.1038/sc.2016.74},
isbn = {1476-5624 (Electronic) 1362-4393 (Linking)},
issn = {14765624},
journal = {Spinal Cord},
number = {12},
pages = {1215--1219},
pmid = {27241446},
title = {{Spinal cord injury and Parkinson's disease: A population-based, propensity score-matched, longitudinal follow-up study}},
volume = {54},
year = {2016}
}
@article{Dillies2013,
abstract = {During the last 3 years, a number of approaches for the normalization of RNA sequencing data have emerged in the literature, differing both in the type of bias adjustment and in the statistical strategy adopted. However, as data continue to accumulate, there has been no clear consensus on the appropriate normalization method to be used or the impact of a chosen method on the downstream analysis. In this work, we focus on a comprehensive comparison of seven recently proposed normalization methods for the differential analysis of RNA-seq data, with an emphasis on the use of varied real and simulated datasets involving different species and experimental designs to represent data characteristics commonly observed in practice. Based on this comparison study, we propose practical recommendations on the appropriate normalization method to be used and its impact on the differential analysis of RNA-seq data.},
author = {Dillies, Marie Agn{\`{e}}s and Rau, Andrea and Aubert, Julie and Hennequet-Antier, Christelle and Jeanmougin, Marine and Servant, Nicolas and Keime, C{\'{e}}line and Marot, Nicolas Servant and Castel, David and Estelle, Jordi and Guernec, Gregory and Jagla, Bernd and Jouneau, Luc and Lalo{\"{e}}, Denis and {Le Gall}, Caroline and Scha{\"{e}}ffer, Brigitte and {Le Crom}, St{\'{e}}phane and Guedj, Micka{\"{e}}l and Jaffr{\'{e}}zic, Florence},
doi = {10.1093/bib/bbs046},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Dillies et al. - 2013 - A comprehensive evaluation of normalization methods for Illumina high-throughput RNA sequencing data analysis(2).pdf:pdf},
isbn = {1477-4054 (Electronic)$\backslash$r1467-5463 (Linking)},
issn = {14675463},
journal = {Briefings in Bioinformatics},
keywords = {Differential analysis,High-throughput sequencing,Normalization,RNA-seq},
pmid = {22988256},
title = {{A comprehensive evaluation of normalization methods for Illumina high-throughput RNA sequencing data analysis}},
year = {2013}
}
@article{CostaRighelli2017,
abstract = {Vaccination is the most successful and cost-effective method to prevent infectious diseases. However, many vaccine antigens have poor in vivo immunogenic potential and need adjuvants to enhance immune response. The application of systems biology to immunity and vaccinology has yielded crucial insights about how vaccines and adjuvants work. We have previously characterized two safe and powerful delivery systems derived from non-pathogenic prokaryotic organisms: E2 and fd filamentous bacteriophage systems. They elicit an in vivo immune response inducing CD8+ T-cell responses, even in absence of adjuvants or stimuli for dendritic cells' maturation. Nonetheless, a systematic and comparative analysis of the complex gene expression network underlying such activation is missing. Therefore, we compared the transcriptomes of ex vivo isolated bone marrow-derived dendritic cells exposed to these antigen delivery systems. Significant differences emerged, especially for genes involved in innate immunity, co-stimulation, and cytokine production. Results indicate that E2 drives polarization toward the Th2 phenotype, mainly mediated by Irf4, Ccl17, and Ccr4 over-expression. Conversely, fd-sc$\alpha$DEC-205 triggers Th1 T cells' polarization through the induction of Il12b, Il12rb, Il6, and other molecules involved in its signal transduction. The data analysis was performed using RNASeqGUI, hence, addressing the increasing need of transparency and reproducibility of computational analysis.},
author = {Costa, Valerio and Righelli, Dario and Russo, Francesco and {De Berardinis}, Piergiuseppe and Angelini, Claudia and D'Apice, Luciana},
doi = {10.3390/ijms18030494},
issn = {14220067},
journal = {International Journal of Molecular Sciences},
keywords = {Dendritic cells,RNA-Sequencing,Reproducible research,System vaccinology},
number = {3},
pmid = {28245601},
title = {{Distinct antigen delivery systems induce dendritic cells' divergent transcriptional response: New insights from a comparative and reproducible computational analysis}},
volume = {18},
year = {2017}
}
@article{Zhang2008,
abstract = {We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.},
author = {Zhang, Yong and Liu, Tao and Meyer, Clifford A. and Eeckhoute, J{\'{e}}r{\^{o}}me and Johnson, David S. and Bernstein, Bradley E. and Nussbaum, Chad and Myers, Richard M. and Brown, Myles and Li, Wei and Shirley, X. Shirley},
doi = {10.1186/gb-2008-9-9-r137},
isbn = {1474-760X},
issn = {14747596},
journal = {Genome Biology},
pmid = {18798982},
title = {{Model-based analysis of ChIP-Seq (MACS)}},
year = {2008}
}
@misc{tcga2013a,
abstract = {The Cancer Genome Atlas (TCGA) is a comprehensive and coordinated effort to accelerate our understanding of the molecular basis of cancer through the application of genome analysis technologies, including large-scale genome sequencing.},
author = {{The Cancer Genoma Atlas}},
booktitle = {National Cancer Institute (NCI) and National Human Genome Research Institute (NHGRI)},
title = {{TCGA}},
year = {2013}
}
@article{Thorvaldsdottir2013,
abstract = {Data visualization is an essential component of genomic data analysis. However, the size and diversity of the data sets produced by today's sequencing and array-based profiling methods present major challenges to visualization tools. The Integrative Genomics Viewer (IGV) is a high-performance viewer that efficiently handles large heterogeneous data sets, while providing a smooth and intuitive user experience at all levels of genome resolution. A key characteristic of IGV is its focus on the integrative nature of genomic studies, with support for both array-based and next-generation sequencing data, and the integration of clinical and phenotypic data. Although IGV is often used to view genomic data from public sources, its primary emphasis is to support researchers who wish to visualize and explore their own data sets or those from colleagues. To that end, IGV supports flexible loading of local and remote data sets, and is optimized to provide high-performance data visualization and exploration on standard desktop systems. IGV is freely available for download from http://www.broadinstitute.org/igv, under a GNU LGPL open-source license.},
archivePrefix = {arXiv},
arxivId = {1706.05554},
author = {Thorvaldsd{\'{o}}ttir, Helga and Robinson, James T. and Mesirov, Jill P.},
doi = {10.1093/bib/bbs017},
eprint = {1706.05554},
isbn = {1477-4054 (Electronic)$\backslash$r1467-5463 (Linking)},
issn = {14675463},
journal = {Briefings in Bioinformatics},
keywords = {Genome viewer,IGV,NGS,Next-generation sequencing,Visualization},
number = {2},
pages = {178--192},
pmid = {22517427},
title = {{Integrative Genomics Viewer (IGV): High-performance genomics data visualization and exploration}},
volume = {14},
year = {2013}
}
@article{Meng2016,
abstract = {State-of-the-art next-generation sequencing, transcriptomics, proteomics and other high-throughput 'omics' technologies enable the efficient generation of large experimental data sets. These data may yield unprecedented knowledge about molecular pathways in cells and their role in disease. Dimension reduction approaches have been widely used in exploratory analysis of single omics data sets. This review will focus on dimension reduction approaches for simultaneous exploratory analyses of multiple data sets. These methods extract the linear relationships that best explain the correlated structure across data sets, the variability both within and between variables (or observations) and may highlight data issues such as batch effects or outliers. We explore dimension reduction techniques as one of the emerging approaches for data integration, and how these can be applied to increase our understanding of biological systems in normal physiological function and disease.},
author = {Meng, Chen and Zeleznik, Oana A. and Thallinger, Gerhard G. and Kuster, Bernhard and Gholami, Amin M. and Culhane, Aed{\'{i}}n C.},
doi = {10.1093/bib/bbv108},
isbn = {1477-4054 (Electronic)},
issn = {14774054},
journal = {Briefings in Bioinformatics},
keywords = {Dimension reduction,Exploratory data analysis,Integrative genomics,Multi-assay,Multi-omics data integration,Multivariate analysis},
number = {4},
pages = {628--641},
pmid = {26969681},
title = {{Dimension reduction techniques for the integrative analysis of multi-omics data}},
volume = {17},
year = {2016}
}
@article{Robinson2007,
abstract = {Motivation: Digital gene expression (DGE) technologies measure gene expression by counting sequence tags. They are sensitive technologies for measuring gene expression on a genomic scale, without the need for prior knowledge of the genome sequence. As the cost of sequencing DNA decreases, the number of DGE datasets is expected to grow dramatically.$\backslash$nVarious tests of differential expression have been proposed for replicated DGE data using binomial, Poisson, negative binomial or pseudo-likelihood (PL) models for the counts, but none of the these are usable when the number of replicates is very small.$\backslash$nResults: We develop tests using the negative binomial distribution to model overdispersion relative to the Poisson, and use conditional weighted likelihood to moderate the level of overdispersion across genes. Not only is our strategy applicable even with the smallest number of libraries, but it also proves to be more powerful than previous strategies when more libraries are available. The methodology is equally applicable to other counting technologies, such as proteomic spectral counts.$\backslash$nAvailability: An R package can be accessed from http://bioinf.wehi.edu.au/resources/$\backslash$nContact: smyth@wehi.edu.au$\backslash$nSupplementary information: http://bioinf.wehi.edu.au/resources/},
author = {Robinson, Mark D. and Smyth, Gordon K.},
doi = {10.1093/bioinformatics/btm453},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {21},
pages = {2881--2887},
pmid = {17881408},
title = {{Moderated statistical tests for assessing differences in tag abundance}},
volume = {23},
year = {2007}
}
@article{Gentleman2004,
abstract = {The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.},
author = {Gentleman, RC and Carey, VJ and Bates, DM and Bolstad, B and Dettling, M and Dudoit, S and Ellis, B and Gautier, L and Ge, Y and Gentry, J and Hornik, K and Hothorn, T and Huber, W and Iacus, S and Irizarry, R and Leisch, F and Li, C and Maechler, M and Rossini, AJ and Sawitzki, G and Smith, C and Smyth, G and Tierney, L and Yang, JYH and Zhang, J},
doi = {10.1186/gb-2004-5-10-r80},
isbn = {1465-6914 (Electronic)$\backslash$n1465-6906 (Linking)},
issn = {1465-6914},
journal = {Genome Biology},
pmid = {15461798},
title = {{Bioconductor: open software development for computational biology and bioinformatics.}},
year = {2004}
}
@article{Services2007,
abstract = {The Examination of gene expression using high-throughput methodologies has become very popular in recent years. Techniques such as microarray hybridization and serial analysis of gene expression (SAGE) allow the simultaneous quantification of tens of thou- sands of gene transcripts. The Gene Expression Omnibus (GEO) is a public repository that archives and freely distributes high- throughput gene expression data submitted by the scientific community. GEO currently stores approximately a billion individual gene expression measurements, derived from over 100 organisms, addressing a wide range of biological issues. These huge volumes of data may be effectively explored, queried, and visualized using user-friendly Web-based tools. GEO is accessible at www.ncbi.nlm.nih.gov/geo},
author = {Services, Human},
isbn = {3014809241},
journal = {Gene Expression},
number = {Figure 1},
pages = {2--3},
title = {{GEO : the Gene Expression Omnibus}},
url = {http://www.ncbi.nlm.nih.gov/geo/},
volume = {23},
year = {2007}
}
@article{Pepke2009,
abstract = {Genome-wide measurements of protein-DNA interactions and transcriptomes are increasingly done by deep DNA sequencing methods (ChIP-seq and RNA-seq). The power and richness of these counting-based measurements comes at the cost of routinely handling tens to hundreds of millions of reads. Whereas early adopters necessarily developed their own custom computer code to analyze the first ChIP-seq and RNA-seq datasets, a new generation of more sophisticated algorithms and software tools are emerging to assist in the analysis phase of these projects. Here we describe the multilayered analyses of ChIP-seq and RNA-seq datasets, discuss the software packages currently available to perform tasks at each layer and describe some upcoming challenges and features for future analysis tools. We also discuss how software choices and uses are affected by specific aspects of the underlying biology and data structure, including genome size, positional clustering of transcription factor binding sites, transcript discovery and expression quantification.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Pepke, Shirley and Wold, Barbara and Mortazavi, Ali},
doi = {10.1038/nmeth.1371},
eprint = {NIHMS150003},
isbn = {1548-7091},
issn = {15487105},
journal = {Nature Methods},
number = {11S},
pages = {S22},
pmid = {19844228},
title = {{Computation for chip-seq and rna-seq studies}},
volume = {6},
year = {2009}
}
@article{Lun2015,
abstract = {Chromatin immunoprecipitation with massively parallel sequencing (ChIP-seq) is widely used to identify binding sites for a target protein in the genome. An important scientific application is to identify changes in protein binding between different treatment conditions, i.e. to detect differential binding. This can reveal potential mechanisms through which changes in binding may contribute to the treatment effect. The csaw package provides a framework for the de novo detection of differentially bound genomic regions. It uses a window-based strategy to summarize read counts across the genome. It exploits existing statistical software to test for significant differences in each window. Finally, it clusters windows into regions for output and controls the false discovery rate properly over all detected regions. The csaw package can handle arbitrarily complex experimental designs involving biological replicates. It can be applied to both transcription factor and histone mark datasets, and, more generally, to any type of sequencing data measuring genomic coverage. csaw performs favorably against existing methods for de novo DB analyses on both simulated and real data. csaw is implemented as a R software package and is freely available from the open-source Bioconductor project.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lun, Aaron T.L. and Smyth, Gordon K.},
doi = {10.1093/nar/gkv1191},
eprint = {arXiv:1011.1669v3},
isbn = {9780874216561},
issn = {13624962},
journal = {Nucleic Acids Research},
number = {5},
pmid = {26578583},
title = {{Csaw: A Bioconductor package for differential binding analysis of ChIP-seq data using sliding windows}},
volume = {44},
year = {2015}
}
@article{Righelli2018,
author = {Righelli, Dario and Koberstein, John and Zhang, Nancy and Angelini, Claudia and Peixoto, Lucia and Risso, Davide},
doi = {10.7287/peerj.preprints.27357v1},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Righelli et al. - 2018 - Differential Enriched Scan 2 (DEScan2) a fast pipeline for broad peak analysis.pdf:pdf},
issn = {2167-9843},
journal = {PeerJ},
keywords = {atac-seq,bioinformatics,epigenomics,peak calling,pipeline},
month = {nov},
publisher = {PeerJ Inc.},
title = {{Differential Enriched Scan 2 (DEScan2): a fast pipeline for broad peak analysis}},
url = {https://peerj.com/preprints/27357/},
year = {2018}
}
@article{Koberstein2018,
abstract = {Autism spectrum disorder (ASD) is a prevalent neurodevelopmental disorder that is associated with genetic risk factors. Most human disease-associated single-nucleotide polymorphisms (SNPs) are not located in genes but rather are in regulatory regions that control gene expression. The function of regulatory regions is determined through epigenetic mechanisms. Parallels between the cellular basis of development and the formation of long-term memory have long been recognized, particularly the role of epigenetic mechanisms in both processes. We analyzed how learning alters chromatin accessibility in the mouse hippocampus using a new high-throughput sequencing bioinformatics strategy we call DEScan (differential enrichment scan). DEScan, which enabled the analysis of data from epigenomic experiments containing multiple replicates, revealed changes in chromatin accessibility at 2365 regulatory regions-most of which were promoters. Learning-regulated promoters were active during forebrain development in mice and were enriched in epigenetic modifications indicative of bivalent promoters. These promoters were disproportionally intronic, showed a complex relationship with gene expression and alternative splicing during memory consolidation and retrieval, and were enriched in the data set relative to known ASD risk genes. Genotyping in a clinical cohort within one of these promoters (SHANK3 promoter 6) revealed that the SNP rs6010065 was associated with ASD. Our data support the idea that learning recapitulates development at the epigenetic level and demonstrate that behaviorally induced epigenetic changes in mice can highlight regulatory regions relevant to brain disorders in patients.},
author = {Koberstein, John N. and Poplawski, Shane G. and Wimmer, Mathieu E. and Porcari, Giulia and Kao, Charlly and Gomes, Bruce and Risso, Davide and Hakonarson, Hakon and Zhang, Nancy R. and Schultz, Robert T. and Abel, Ted and Peixoto, Lucia},
doi = {10.1126/scisignal.aan6500},
isbn = {1937-9145},
issn = {19379145},
journal = {Science Signaling},
pmid = {29339533},
title = {{Learning-dependent chromatin remodeling highlights noncoding regulatory regions linked to autism}},
year = {2018}
}
@misc{Costa-Silva2017,
abstract = {The correct identification of differentially expressed genes (DEGs) between specific conditions is a key in the understanding phenotypic variation. High-throughput transcriptome sequencing (RNA-Seq) has become the main option for these studies. Thus, the number of methods and softwares for differential expression analysis from RNA-Seq data also increased rapidly. However, there is no consensus about the most appropriate pipeline or protocol for identifying differentially expressed genes from RNA-Seq data. This work presents an extended review on the topic that includes the evaluation of six methods of mapping reads, including pseudo-alignment and quasi-mapping and nine methods of differential expression analysis from RNA-Seq data. The adopted methods were evaluated based on real RNA-Seq data, using qRT-PCR data as reference (gold-standard). As part of the results, we developed a software that performs all the analysis presented in this work, which is freely available at https://github.com/costasilvati/consexpression. The results indicated that mapping methods have minimal impact on the final DEGs analysis, considering that adopted data have an annotated reference genome. Regarding the adopted experimental model, the DEGs identification methods that have more consistent results were the limma+voom, NOIseq and DESeq2. Additionally, the consensus among five DEGs identification methods guarantees a list of DEGs with great accuracy, indicating that the combination of different methods can produce more suitable results. The consensus option is also included for use in the available software.},
archivePrefix = {arXiv},
arxivId = {arXiv:1804.06050v3},
author = {Costa-Silva, Juliana and Domingues, Douglas and Lopes, Fabricio Martins},
booktitle = {PLoS ONE},
doi = {10.1371/journal.pone.0190152},
eprint = {arXiv:1804.06050v3},
isbn = {1111111111},
issn = {19326203},
pmid = {29267363},
title = {{RNA-Seq differential expression analysis: An extended review and a software tool}},
year = {2017}
}
@misc{Wang2009,
abstract = {RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Wang, Zhong and Gerstein, Mark and Snyder, Michael},
booktitle = {Nature Reviews Genetics},
doi = {10.1038/nrg2484},
eprint = {NIHMS150003},
isbn = {1471-0064 (Electronic)$\backslash$r1471-0056 (Linking)},
issn = {14710056},
number = {1},
pages = {57--63},
pmid = {19015660},
title = {{RNA-Seq: A revolutionary tool for transcriptomics}},
volume = {10},
year = {2009}
}
@article{SummExp,
abstract = {The SummarizedExperiment container contains one or more assays, each represented by a matrix-like object of numeric or other mode. The rows typically represent genomic ranges of interest and the columns represent samples.},
author = {{Morgan M, Obenchain V, Hester J}, Pag{\`{e}}s H},
doi = {https://doi.org/doi:10.18129/B9.bioc.SummarizedExperiment},
title = {{SummarizedExperiment: SummarizedExperiment container}},
year = {2018}
}
@article{Aranguren2015,
abstract = {BACKGROUND: Semantic Web technologies have been widely applied in the life sciences, for example by data providers such as OpenLifeData and through web services frameworks such as SADI. The recently reported OpenLifeData2SADI project offers access to the vast OpenLifeData data store through SADI services.$\backslash$n$\backslash$nFINDINGS: This article describes how to merge data retrieved from OpenLifeData2SADI with other SADI services using the Galaxy bioinformatics analysis platform, thus making this semantic data more amenable to complex analyses. This is demonstrated using a working example, which is made distributable and reproducible through a Docker image that includes SADI tools, along with the data and workflows that constitute the demonstration.$\backslash$n$\backslash$nCONCLUSIONS: The combination of Galaxy and Docker offers a solution for faithfully reproducing and sharing complex data retrieval and analysis workflows based on the SADI Semantic web service design patterns.},
author = {Aranguren, Mikel Ega{\~{n}}a and Wilkinson, Mark D.},
doi = {10.1186/s13742-015-0092-3},
issn = {2047217X},
journal = {GigaScience},
keywords = {Docker,Galaxy,RDF,Reproducibility,SADI,Semantic Web,Web service,Workflow},
number = {1},
pmid = {26640691},
title = {{Enhanced reproducibility of SADI web service workflows with Galaxy and Docker}},
volume = {4},
year = {2015}
}
@article{Wang2014,
abstract = {Recent technologies have made it cost-effective to collect diverse types of genome-wide data. Computational methods are needed to combine these data to create a comprehensive view of a given disease or a biological process. Similarity network fusion (SNF) solves this problem by constructing networks of samples (e.g., patients) for each available data type and then efficiently fusing these into one network that represents the full spectrum of underlying data. For example, to create a comprehensive view of a disease given a cohort of patients, SNF computes and fuses patient similarity networks obtained from each of their data types separately, taking advantage of the complementarity in the data. We used SNF to combine mRNA expression, DNA methylation and microRNA (miRNA) expression data for five cancer data sets. SNF substantially outperforms single data type analysis and established integrative approaches when identifying cancer subtypes and is effective for predicting survival.},
author = {Wang, Bo and Mezlini, Aziz M. and Demir, Feyyaz and Fiume, Marc and Tu, Zhuowen and Brudno, Michael and Haibe-Kains, Benjamin and Goldenberg, Anna},
doi = {10.1038/nmeth.2810},
isbn = {doi:10.1038/nmeth.2810},
issn = {15487105},
journal = {Nature Methods},
number = {3},
pages = {333--337},
pmid = {24464287},
title = {{Similarity network fusion for aggregating data types on a genomic scale}},
volume = {11},
year = {2014}
}
@article{Jia2017,
abstract = {In recent years, next generation sequencing (NGS) has gradually replaced microarray as the major platform in measuring gene expressions. Compared to microarray, NGS has many advantages, such as less noise and higher throughput. However, the discreteness of NGS data also challenges the existing statistical methodology. In particular, there still lacks an appropriate statistical method for reconstructing gene regulatory networks using NGS data in the literature. The existing local Poisson graphical model method is not consistent and can only infer certain local structures of the network. In this article, we propose a random effect model-based transformation to continuize NGS data and then we transform the continuized data to Gaussian via a semiparametric transformation and apply an equivalent partial correlation selection method to reconstruct gene regulatory networks. The proposed method is consistent. The numerical results indicate that the proposed method can lead to much more accurate inference of gene regulatory networks than the local Poisson graphical model and other existing methods. The proposed data-continuized transformation fills the theoretical gap for how to transform discrete data to continuous data and facilitates NGS data analysis. The proposed data-continuized transformation also makes it feasible to integrate different types of data, such as microarray and RNA-seq data, in reconstruction of gene regulatory networks.},
author = {Jia, Bochao and Xu, Suwa and Xiao, Guanghua and Lamba, Vishal and Liang, Faming},
doi = {10.1111/biom.12682},
issn = {15410420},
journal = {Biometrics},
keywords = {Data-continuized transformation,Gaussian graphical model,Gene regulatory network,Poisson graphical model,RNA-seq},
number = {4},
pages = {1221--1230},
pmid = {28294287},
title = {{Learning gene regulatory networks from next generation sequencing data}},
volume = {73},
year = {2017}
}
@article{Zhu2010,
abstract = {BACKGROUND Chromatin immunoprecipitation (ChIP) followed by high-throughput sequencing (ChIP-seq) or ChIP followed by genome tiling array analysis (ChIP-chip) have become standard technologies for genome-wide identification of DNA-binding protein target sites. A number of algorithms have been developed in parallel that allow identification of binding sites from ChIP-seq or ChIP-chip datasets and subsequent visualization in the University of California Santa Cruz (UCSC) Genome Browser as custom annotation tracks. However, summarizing these tracks can be a daunting task, particularly if there are a large number of binding sites or the binding sites are distributed widely across the genome. RESULTS We have developed ChIPpeakAnno as a Bioconductor package within the statistical programming environment R to facilitate batch annotation of enriched peaks identified from ChIP-seq, ChIP-chip, cap analysis of gene expression (CAGE) or any experiments resulting in a large number of enriched genomic regions. The binding sites annotated with ChIPpeakAnno can be viewed easily as a table, a pie chart or plotted in histogram form, i.e., the distribution of distances to the nearest genes for each set of peaks. In addition, we have implemented functionalities for determining the significance of overlap between replicates or binding sites among transcription factors within a complex, and for drawing Venn diagrams to visualize the extent of the overlap between replicates. Furthermore, the package includes functionalities to retrieve sequences flanking putative binding sites for PCR amplification, cloning, or motif discovery, and to identify Gene Ontology (GO) terms associated with adjacent genes. CONCLUSIONS ChIPpeakAnno enables batch annotation of the binding sites identified from ChIP-seq, ChIP-chip, CAGE or any technology that results in a large number of enriched genomic regions within the statistical programming environment R. Allowing users to pass their own annotation data such as a different Chromatin immunoprecipitation (ChIP) preparation and a dataset from literature, or existing annotation packages, such as GenomicFeatures and BSgenome, provides flexibility. Tight integration to the biomaRt package enables up-to-date annotation retrieval from the BioMart database.},
author = {Zhu, Lihua J. and Gazin, Claude and Lawson, Nathan D. and Pag{\`{e}}s, Herv{\'{e}} and Lin, Simon M. and Lapointe, David S. and Green, Michael R.},
doi = {10.1186/1471-2105-11-237},
isbn = {1471-2105},
issn = {14712105},
journal = {BMC Bioinformatics},
pmid = {20459804},
title = {{ChIPpeakAnno: A Bioconductor package to annotate ChIP-seq and ChIP-chip data}},
year = {2010}
}
@article{Peixoto2015,
abstract = {The sequencing of the full transcriptome (RNA-seq) has become the preferred choice for the measurement of genome-wide gene expression. Despite its widespread use, challenges remain in RNA-seq data analysis. One often-overlooked aspect is normalization. Despite the fact that a variety of factors or ‘batch effects' can contribute unwanted variation to the data, commonly used RNA-seq normalization methods only correct for sequencing depth. The study of gene expression is particularly problematic when it is influenced simultaneously by a variety of biological factors in addition to the one of interest. Using examples from experimental neuroscience, we show that batch effects can dominate the signal of interest; and that the choice of normalization method affects the power and reproducibility of the results. While commonly used global normalization methods are not able to adequately normalize the data, more recently developed RNA-seq normalization can. We focus on one particular method, RUVSeq and show that it is able to increase power and biological insight of the results. Finally, we provide a tutorial outlining the implementation of RUVSeq normalization that is applicable to a broad range of studies as well as meta-analysis of publicly available data.},
author = {Peixoto, Lucia and Risso, Davide and Poplawski, Shane G. and Wimmer, Mathieu E. and Speed, Terence P. and Wood, Marcelo A. and Abel, Ted},
doi = {10.1093/nar/gkv736},
isbn = {0305-1048},
issn = {13624962},
journal = {Nucleic Acids Research},
pmid = {26202970},
title = {{Survey and Summary: How data analysis affects power, reproducibility and biological insight of RNA-seq studies in complex datasets}},
year = {2015}
}
@article{Tarazona2012,
abstract = {http://bioinfo.cipf.es/aconesa     Introduction  Next Generation Sequencing (NGS) technologies have brought a revolution to research in genome and genome regulation. One of the most breaking applications of NGS is in transcriptome analysis. RNA-seq has revealed exciting new data on gene models, alternative splicing and extra-genic expression. Also RNA-seq permits the quantification of gene expression across a large dynamic range and with more reproducibility than microarrays. Several methods for the assessment of differential expression from count data have been proposed but biases associated to transcript length and transcript frequency distributions have been reported. It is still not clear how much sequencing reads should be generated in a RNA-seq experiment to obtain reliable results and what's exactly being detected. In general we observed that many RNA-seq datasets have not reached saturation for detection of expressed genes and that the relative proportion of different transcript biotypes changes with increasing sequencing depth. In this work we investigate the effect that library size has on the assessment of differential expression on different aspects of the selected genes. We show that current statistical methods suffer from a strong dependency of their significant calls on the number of mapped reads considered and proposed a novel differential expression methodology – NOISeq1- that is robust to the amount of reads.    Results  NOISeq is a non-parametric approach for the differential expression analysis of RNseq-data. NOISeq creates a null or noise distribution of count changes by comparing the number of reads of each gene in samples within the same condition. This reference distribution is then used to assess whether the change in count number between two conditions for a given gene is likely to be part of the noise or represents a true differential expression. Two variants of the method are implemented: NOISeq-real uses replicates, when available, to compute the noise distribution and, NOISeq-sim simulates them in absence of replication. We compared our method with edgeR2, DESeq3, baySeq4 and Fisher Exact Test (FET) using three different experimental datasets. Results are presented for MAQC experiment where the transcriptome of brain and Universal Human Reference (HUR) samples were sequenced at about 45 million Solexa reads each.   We first determined that although protein-coding gene is the most abundant transcript type within differential expression calls for all methodologies, other RNA types, such as processed-transcript, pseudogenes and lincRNAs are readily detected. NOISeq dected comparatively more protein-coding genes than other methods that called significant a considerable number of non-coding and small RNA transcripts. Additionally, all comparing methods except FET greatly increased the number of detected (non-coding) genes as sequencing depth raised while NOISeq showed a constant pattern. Also these other methods tend to select shorter genes and smaller fold change differences with the increasing amounts of reads. In general, parametric approaches selected much more genes than NOISeq, specially at high sequencing depth rates. When analyzing the functional content of these genes by functional enrichment analysis, we observed that the pool of genes detected both by NOISeq and the parametric methods where highly enriched in functional categories, while genes selected only by parametric methods did not. To check whether this differences were indicative of different false calls between methods, we used the RT-PCR data available at the MAQC project that contains 330 true positive and 83 true negative differentially expressed genes. Performance plots indicate that edgeR, DESeq, baySeq strongly increased the number of false calls with sequencing depth, while NOISeq was constant and low. On the contrary true discoveries were slightly better for these methods, presumably consequence of their large number of selected genes. FET showed in low false and true discovery rates, due to its general lower detection power.    Conclusions  We showed that most current RNA-seq statistical analysis methods fail to control the number of false discoveries as the size of the sequenced library increases. These false positive are mainly short, non- coding genes and/or genes with small fold changes. NOISeq, but adopting an empirical approach to model the null distribution of differential expression captures better the shape of noise in RNA-seq data, resulting in a sequencing-depth robust method for differential expression analysis.    References  1. Tarazona S., Garcia-Alcalde F., Ferrer A., Dopazo J., Conesa, A. Differential expression in RNA-seq:a matter of depth. Genome Research, Sep 2011, doi:10.1101/gr.124321.11. 2. Robinson, MD, McCarthy, DJ, and Smyth, GK. 2010. edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics 26(1):139,140. 3. Anders, S and Huber, W. 2010. Differential expression analysis for sequence count data. Genome Biology 11(10):R106. 4. Hardcastle, T and Kelly, K. 2010. baySeq: Empirical Bayesian methods for identifying differential expression in sequence count data. BMC Bioinformatics 11(1):422+.    Relevant Web sites  5. http://bioinfo.cipf.es/noiseq},
author = {Tarazona, Sonia and Garc{\'{i}}a, Fernando and Ferrer, Alberto and Dopazo, Joaqu{\'{i}}n and Conesa, Ana},
doi = {10.14806/ej.17.B.265},
isbn = {1023-4144},
issn = {2226-6089},
journal = {EMBnet.journal},
keywords = {COST,RNA-seq,differential expression,next generation sequencing,non-parametric approach},
number = {B},
pages = {18},
title = {{NOIseq: a RNA-seq differential expression method robust for sequencing depth biases}},
url = {http://journal.embnet.org/index.php/embnetjournal/article/view/265},
volume = {17},
year = {2012}
}
@article{Risso2014h,
abstract = {Normalization of RNA-sequencing (RNA-seq) data has proven essential to ensure accurate inference of expression levels. Here, we show that usual normalization approaches mostly account for sequencing depth and fail to correct for library preparation and other more complex unwanted technical effects. We evaluate the performance of the External RNA Control Consortium (ERCC) spike-in controls and investigate the possibility of using them directly for normalization. We show that the spike-ins are not reliable enough to be used in standard global-scaling or regression-based normalization procedures. We propose a normalization strategy, called remove unwanted variation (RUV), that adjusts for nuisance technical effects by performing factor analysis on suitable sets of control genes (e.g., ERCC spike-ins) or samples (e.g., replicate libraries). Our approach leads to more accurate estimates of expression fold-changes and tests of differential expression compared to state-of-the-art normalization methods. In particular, RUV promises to be valuable for large collaborative projects involving multiple laboratories, technicians, and/or sequencing platforms.},
author = {Risso, Davide and Ngai, John and Speed, Terence P and Dudoit, Sandrine},
doi = {10.1038/nbt.2931},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Risso et al. - 2014 - Normalization of RNA-seq data using factor analysis of control genes or samples (RUVSeq).pdf:pdf},
isbn = {1087-0156 1546-1696},
issn = {1087-0156},
journal = {Nature Biotechnology},
keywords = {next generation sequencing,ngs,normalization,rna-seq},
mendeley-tags = {next generation sequencing,ngs,normalization,rna-seq},
number = {9},
pages = {896--902},
pmid = {25150836},
title = {{Normalization of RNA-seq data using factor analysis of control genes or samples (RUVSeq)}},
url = {http://dx.doi.org/10.1038/nbt.2931},
volume = {32},
year = {2014}
}
@article{Liao2013,
abstract = {Read alignment is an ongoing challenge for the analysis of data from sequencing technologies. This article proposes an elegantly simple multi-seed strategy, called seed-and-vote, for mapping reads to a reference genome. The new strategy chooses the mapped genomic location for the read directly from the seeds. It uses a relatively large number of short seeds (called subreads) extracted from each read and allows all the seeds to vote on the optimal location. When the read length is {\textless}160 bp, overlapping subreads are used. More conventional alignment algorithms are then used to fill in detailed mismatch and indel information between the subreads that make up the winning voting block. The strategy is fast because the overall genomic location has already been chosen before the detailed alignment is done. It is sensitive because no individual subread is required to map exactly, nor are individual subreads constrained to map close by other subreads. It is accurate because the final location must be supported by several different subreads. The strategy extends easily to find exon junctions, by locating reads that contain sets of subreads mapping to different exons of the same gene. It scales up efficiently for longer reads.},
author = {Liao, Yang and Smyth, Gordon K. and Shi, Wei},
doi = {10.1093/nar/gkt214},
isbn = {1362-4962 (Electronic)$\backslash$n0305-1048 (Linking)},
issn = {03051048},
journal = {Nucleic Acids Research},
pmid = {23558742},
title = {{The Subread aligner: Fast, accurate and scalable read mapping by seed-and-vote}},
year = {2013}
}
@misc{Thermes2014,
abstract = {Ten years ago next-generation sequencing (NGS) technologies appeared on the market. During the past decade, tremendous progress has been made in terms of speed, read length, and throughput, along with a sharp reduction in per-base cost. Together, these advances democratized NGS and paved the way for the development of a large number of novel NGS applications in basic science as well as in translational research areas such as clinical diagnostics, agrigenomics, and forensic science. Here we provide an overview of the evolution of NGS and discuss the most significant improvements in sequencing technologies and library preparation protocols. We also explore the current landscape of NGS applications and provide a perspective for future developments.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.0570v2},
author = {Thermes, Claude},
booktitle = {Trends in genetics : TIG},
doi = {10.1016/j.tig.2014.07.001},
eprint = {arXiv:1312.0570v2},
isbn = {01689525},
issn = {01689525},
keywords = {ChIP-seq,DNA-seq,NGS library preparation,Next-generation sequencing (NGS),RNA-seq,genomics},
number = {9},
pages = {418--426},
pmid = {25108476},
title = {{Ten years of next-generation sequencing technology}},
volume = {30},
year = {2014}
}
@article{Kim2013,
abstract = {TopHat is a popular spliced aligner for RNA-sequence (RNA-seq) experiments. In this paper, we describe TopHat2, which incorporates many significant enhancements to TopHat. TopHat2 can align reads of various lengths produced by the latest sequencing technologies, while allowing for variable-length indels with respect to the reference genome. In addition to de novo spliced alignment, TopHat2 can align reads across fusion breaks, which can occur after genomic translocations. TopHat2 combines the ability to identify novel splice sites with direct mapping to known transcripts, producing sensitive and accurate alignments, even for highly repetitive genomes or in the presence of pseudogenes. TopHat2 is available at http://ccb.jhu.edu/software/tophat.},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Kim, Daehwan and Pertea, Geo and Trapnell, Cole and Pimentel, Harold and Kelley, Ryan and Salzberg, Steven L},
doi = {10.1186/gb-2013-14-4-r36},
eprint = {1512.00567},
isbn = {1465-6914 (Electronic)$\backslash$r1465-6906 (Linking)},
issn = {1474760X},
journal = {Genome biology},
number = {4},
pages = {R36},
pmid = {23618408},
title = {{TopHat2: accurate alignment of transcriptomes in the presence of insertions, deletions and gene fusions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23618408{\%}0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4053844},
volume = {14},
year = {2013}
}
@article{Baggerly2009,
abstract = {High-throughput biological assays such as microarrays let us ask very detailed questions about how diseases operate, and promise to let us personalize therapy. Data processing, however, is often not described well enough to allow for exact reproduction of the results, leading to exercises in "forensic bioinformatics" where aspects of raw data and reported results are used to infer what methods must have been employed. Unfortunately, poor documentation can shift from an inconvenience to an active danger when it obscures not just methods but errors. In this report we examine several related papers purporting to use microarray-based signatures of drug sensitivity derived from cell lines to predict patient response. Patients in clinical trials are currently being allocated to treatment arms on the basis of these results. However, we show in five case studies that the results incorporate several simple errors that may be putting patients at risk. One theme that emerges is that the most common errors are simple (e.g., row or column offsets); conversely, it is our experience that the most simple errors are common. We then discuss steps we are taking to avoid such errors in our own investigations.},
archivePrefix = {arXiv},
arxivId = {1010.1092},
author = {Baggerly, Keith A. and Coombes, Kevin R.},
doi = {10.1214/09-AOAS291},
eprint = {1010.1092},
isbn = {1932-6157},
issn = {19326157},
journal = {Annals of Applied Statistics},
keywords = {Forensic bioinformatics,Microarrays,Reproducibility},
number = {4},
pages = {1309--1334},
pmid = {27630666},
title = {{Deriving chemosensitivity from cell lines: Forensic bioinformatics and reproducible research in high-throughput biology}},
volume = {3},
year = {2009}
}
@article{Hillman-Jackson2012,
abstract = {Innovations in biomedical research technologies continue to provide experimental biologists with novel and increasingly large genomic and high-throughput data resources to be analyzed. As creating and obtaining data has become easier, the key decision faced by many researchers is a practical one: where and how should an analysis be performed? Datasets are large and analysis tool set-up and use is riddled with complexities outside of the scope of core research activities. The authors believe that Galaxy (galaxyproject.org) provides a powerful solution that simplifies data acquisition and analysis in an intuitive web-application, granting all researchers access to key informatics tools previously only available to computational specialists working in Unix-based environments. We will demonstrate through a series of biomedically relevant protocols how Galaxy specifically brings together 1) data retrieval from public and private sources, for example, UCSC's Eukaryote and Microbial Genome Browsers (genome.ucsc.edu), 2) custom tools (wrapped Unix functions, format standardization/conversions, interval operations) and 3rd party analysis tools, for example, Bowtie/Tuxedo Suite (bowtie-bio.sourceforge.net), Lastz (www.bx.psu.edu/{\~{}}rsharris/lastz/), SAMTools (samtools.sourceforge.net), FASTX-toolkit (hannonlab.cshl.edu/fastx{\_}toolkit), and MACS (liulab.dfci.harvard.edu/MACS), and creates results formatted for visualization in tools such as the Galaxy Track Browser (GTB, galaxyproject.org/wiki/Learn/Visualization), UCSC Genome Browser (genome.ucsc.edu), Ensembl (www.ensembl.org), and GeneTrack (genetrack.bx.psu.edu)., Galaxy rapidly has become the most popular choice for integrated next generation sequencing (NGS) analytics and collaboration, where users can perform, document, and share complex analysis within a single interface in an unprecedented number of ways.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Hillman-Jackson, Jennifer and Clements, Dave and Blankenberg, Daniel and Taylor, James and Nekrutenko, Anton and Team, Galaxy},
doi = {10.1002/0471250953.bi1005s38},
eprint = {NIHMS150003},
isbn = {0471250953},
issn = {19343396},
journal = {Current Protocols in Bioinformatics},
keywords = {Comparative genomics,Galaxy,Genome variation,Genomic alignments,Web application},
number = {SUPPL.38},
pmid = {18428782},
title = {{Using galaxy to perform large-scale interactive data analyses}},
year = {2012}
}
@misc{Ozsolak2011,
abstract = {In the few years since its initial application, massively parallel cDNA sequencing, or RNA-seq, has allowed many advances in the characterization and quantification of transcriptomes. Recently, several developments in RNA-seq methods have provided an even more complete characterization of RNA transcripts. These developments include improvements in transcription start site mapping, strand-specific measurements, gene fusion detection, small RNA characterization and detection of alternative splicing events. Ongoing developments promise further advances in the application of RNA-seq, particularly direct RNA sequencing and approaches that allow RNA quantification from very small amounts of cellular materials.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ozsolak, Fatih and Milos, Patrice M.},
booktitle = {Nature Reviews Genetics},
doi = {10.1038/nrg2934},
eprint = {NIHMS150003},
isbn = {1471-0064; 1471-0056},
issn = {14710056},
number = {2},
pages = {87--98},
pmid = {21191423},
title = {{RNA sequencing: Advances, challenges and opportunities}},
volume = {12},
year = {2011}
}
@article{Napolitano2017,
abstract = {Reproducibility in Data Analysis research has long been a significant concern, particularly in the areas of Bioinformatics and Computational Biology. Towards the aim of developing reproducible and reusable processes, Data Analysis management tools can help giving structure and coherence to complex data flows. Nonetheless, improved software quality comes at the cost of additional design and planning effort, which may become impractical in rapidly changing development environments. I propose that an adjustment of focus from processes to data in the management of Bioinformatic pipelines may help improving reproducibility with minimal impact on preexisting development practices. In this paper I introduce the repo
                           R package for bioinformatic analysis management. The tool supports a data-centered philosophy that aims at improving analysis reproducibility and reusability with minimal design overhead. The core of repo lies in its support for easy data storage, retrieval, distribution and annotation. In repo the data analysis flow is derived a posteriori from dependency annotations. The repo package constitutes an unobtrusive data and flow management extension of the R statistical language. Its adoption, together with good development practices, can help improving data analysis management, sharing and reproducibility, especially in the fields of Bioinformatics and Computational Biology.},
author = {Napolitano, Francesco},
doi = {10.1186/s12859-017-1510-6},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Data flows,Data pipelines,R language,Reproducible research},
number = {1},
pmid = {28209127},
title = {{repo: An R package for data-centered management of bioinformatic pipelines}},
volume = {18},
year = {2017}
}
@article{Peng2009,
abstract = {The ability to make scientific findings reproducible is increasingly$\backslash$nimportant. The authors describe a simple framework in which scientists$\backslash$ncan perform and distribute reproducible research via cached computations.$\backslash$nThis article describes a prototype implementation as well as a case$\backslash$nstudy application.},
author = {Peng, Roger D. and Eckel, Sandrah P.},
doi = {10.1109/MCSE.2009.6},
issn = {15219615},
journal = {Computing in Science and Engineering},
number = {1},
pages = {28--34},
title = {{Distributed reproducible research using cached computations}},
volume = {11},
year = {2009}
}
@article{Bullard2010,
abstract = {BACKGROUND: High-throughput sequencing technologies, such as the Illumina Genome Analyzer, are powerful new tools for investigating a wide range of biological and medical questions. Statistical and computational methods are key for drawing meaningful and accurate conclusions from the massive and complex datasets generated by the sequencers. We provide a detailed evaluation of statistical methods for normalization and differential expression (DE) analysis of Illumina transcriptome sequencing (mRNA-Seq) data. RESULTS: We compare statistical methods for detecting genes that are significantly DE between two types of biological samples and find that there are substantial differences in how the test statistics handle low-count genes. We evaluate how DE results are affected by features of the sequencing platform, such as, varying gene lengths, base-calling calibration method (with and without phi X control lane), and flow-cell/library preparation effects. We investigate the impact of the read count normalization method on DE results and show that the standard approach of scaling by total lane counts (e.g., RPKM) can bias estimates of DE. We propose more general quantile-based normalization procedures and demonstrate an improvement in DE detection. CONCLUSIONS: Our results have significant practical and methodological implications for the design and analysis of mRNA-Seq experiments. They highlight the importance of appropriate statistical methods for normalization and DE inference, to account for features of the sequencing platform that could impact the accuracy of results. They also reveal the need for further research in the development of statistical and computational methods for mRNA-Seq.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Bullard, James H. and Purdom, Elizabeth and Hansen, Kasper D. and Dudoit, Sandrine},
doi = {10.1186/1471-2105-11-94},
eprint = {NIHMS150003},
isbn = {1471-2105 (Electronic){\$}\backslash{\$}r1471-2105 (Linking)},
issn = {14712105},
journal = {BMC Bioinformatics},
pmid = {20167110},
title = {{Evaluation of statistical methods for normalization and differential expression in mRNA-Seq experiments}},
volume = {11},
year = {2010}
}
@article{Giardine2005,
abstract = {Accessing and analyzing the exponentially expanding genomic sequence and functional data pose a challenge for biomedical researchers. Here we describe an interactive system, Galaxy, that combines the power of existing genome annotation databases with a simple Web portal to enable users to search remote resources, combine data from independent queries, and visualize the results. The heart of Galaxy is a flexible history system that stores the queries from each user; performs operations such as intersections, unions, and subtractions; and links to other computational tools. Galaxy can be accessed at http://g2.bx.psu.edu.},
author = {Giardine, Belinda and Riemer, Cathy and Hardison, Ross C. and Burhans, Richard and Elnitski, Laura and Shah, Prachi and Zhang, Yi and Blankenberg, Daniel and Albert, Istvan and Taylor, James and Miller, Webb and Kent, W. James and Nekrutenko, Anton},
doi = {10.1101/gr.4086505},
isbn = {1088-9051 (Print)},
issn = {10889051},
journal = {Genome Research},
number = {10},
pages = {1451--1455},
pmid = {16169926},
title = {{Galaxy: A platform for interactive large-scale genome analysis}},
volume = {15},
year = {2005}
}
@article{Cao2018,
author = {Cao, Junyue and Cusanovich, Darren A. and Ramani, Vijay and Aghamirzaie, Delasa and Pliner, Hannah A. and Hill, Andrew J. and Daza, Riza M. and McFaline-Figueroa, Jose L. and Packer, Jonathan S. and Christiansen, Lena and Steemers, Frank J. and Adey, Andrew C. and Trapnell, Cole and Shendure, Jay},
doi = {10.1126/science.aau0730},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Cao et al. - 2018 - Joint profiling of chromatin accessibility and gene expression in thousands of single cells.pdf:pdf},
isbn = {1305901713820},
issn = {0036-8075},
journal = {Science},
number = {August},
pages = {eaau0730},
pmid = {30166440},
title = {{Joint profiling of chromatin accessibility and gene expression in thousands of single cells}},
url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aau0730},
volume = {0730},
year = {2018}
}
@article{GeneOntologyConsortium2015,
abstract = {The Gene Ontology (GO; http://www.geneontology.org) is a community-based bioinformatics resource that supplies information about gene product function using ontologies to represent biological knowledge. Here we describe improvements and expansions to several branches of the ontology, as well as updates that have allowed us to more efficiently disseminate the GO and capture feedback from the research community. The Gene Ontology Consortium (GOC) has expanded areas of the ontology such as cilia-related terms, cell-cycle terms and multicellular organism processes. We have also implemented new tools for generating ontology terms based on a set of logical rules making use of templates, and we have made efforts to increase our use of logical definitions. The GOC has a new and improved web site summarizing new developments and documentation, serving as a portal to GO data. Users can perform GO enrichment analysis, and search the GO for terms, annotations to gene products, and associated metadata across multiple species using the all-new AmiGO 2 browser. We encourage and welcome the input of the research community in all biological areas in our continued effort to improve the Gene Ontology.},
author = {{Gene Ontology Consortium}},
doi = {10.1093/nar/gku1179},
isbn = {13624962 (Electronic)},
issn = {1362-4962},
journal = {Nucleic acids research},
pmid = {25428369},
title = {{Gene Ontology Consortium: going forward.}},
year = {2015}
}
@article{Giresi2007,
abstract = {The vertebrate body is built on a metameric organization which consists of a repetition of functionally equivalent units, each comprising a vertebra, its associated muscles, peripheral nerves and blood vessels. This periodic pattern is established during embryogenesis by the somitogenesis process. Somites are generated in a rhythmic fashion from the presomitic mesoderm and they subsequently differentiate to give rise to the vertebrae and skeletal muscles of the body. Somitogenesis has been very actively studied in the chick embryo since the 19th century and many of the landmark experiments that led to our current understanding of the vertebrate segmentation process have been performed in this organism. Somite formation involves an oscillator, the segmentation clock whose periodic signal is converted into the periodic array of somite boundaries by a spacing mechanism relying on a traveling threshold of FGF signaling regressing in concert with body axis extension. ?? 2004 Elsevier Ireland Ltd. All rights reserved.},
author = {Giresi, Paul G and Kim, Jonghwan and McDaniell, Ryan M and Iyer, Vishwanath R and Lieb, Jason D},
doi = {10.1016/j.mod.2004.05.002},
isbn = {0925-4773 (Print)$\backslash$n0925-4773 (Linking)},
issn = {09254773},
journal = {Genome Res.},
number = {6},
pages = {877--885},
pmid = {15296972},
title = {{FAIRE (Formaldehyde-Assisted Isolation of Regulatory
Elements) isolates active regulatory elements from human
chromatin}},
volume = {17},
year = {2007}
}
@article{Napolitano2013,
abstract = {BACKGROUND An incremental, loosely planned development approach is often used in bioinformatic studies when dealing with custom data analysis in a rapidly changing environment. Unfortunately, the lack of a rigorous software structuring can undermine the maintainability, communicability and replicability of the process. To ameliorate this problem we propose the Leaf system, the aim of which is to seamlessly introduce the pipeline formality on top of a dynamical development process with minimum overhead for the programmer, thus providing a simple layer of software structuring. RESULTS Leaf includes a formal language for the definition of pipelines with code that can be transparently inserted into the user's Python code. Its syntax is designed to visually highlight dependencies in the pipeline structure it defines. While encouraging the developer to think in terms of bioinformatic pipelines, Leaf supports a number of automated features including data and session persistence, consistency checks between steps of the analysis, processing optimization and publication of the analytic protocol in the form of a hypertext. CONCLUSIONS Leaf offers a powerful balance between plan-driven and change-driven development environments in the design, management and communication of bioinformatic pipelines. Its unique features make it a valuable alternative to other related tools.},
author = {Napolitano, Francesco and Mariani-Costantini, Renato and Tagliaferri, Roberto},
doi = {10.1186/1471-2105-14-201},
isbn = {1471-2105 (Linking)},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Bioinformatic pipelines,Data analysis,Python},
number = {1},
pmid = {23786315},
title = {{Bioinformatic pipelines in Python with Leaf}},
volume = {14},
year = {2013}
}
@article{GeneOntologyConsortium2004,
abstract = {The Gene Ontology (GO) project (http://www. geneontology.org/) provides structured, controlled vocabularies and classifications that cover several domains of molecular and cellular biology and are freely available for community use in the annotation of genes, gene products and sequences. Many model organism databases and genome annotation groups use the GO and contribute their annotation sets to the GO resource. The GO database integrates the vocabularies and contributed annotations and provides full access to this information in several formats. Members of the GO Consortium continually work collectively, involving outside experts as needed, to expand and update the GO vocabularies. The GO Web resource also provides access to extensive documentation about the GO project and links to applications that use GO data for functional analyses.},
author = {{Gene Ontology Consortium}},
doi = {10.1093/nar/gkh036},
isbn = {1362-4962 (Electronic)},
issn = {1362-4962},
journal = {Nucleic Acids Research},
pmid = {14681407},
title = {{The Gene Ontology (GO) database and informatics resource}},
year = {2004}
}
@article{Karolchik2011,
abstract = {The University of California Santa Cruz (UCSC) Genome Browser is a popular Web-based tool for quickly displaying a requested portion of a genome at any scale, accompanied by a series of aligned annotation "tracks." The annotations-generated by the UCSC Genome Bioinformatics Group and external collaborators-display gene predictions, mRNA and expressed sequence tag alignments, simple nucleotide polymorphisms, expression and regulatory data, phenotype and variation data, and pairwise and multiple-species comparative genomics data. All information relevant to a region is presented in one window, facilitating biological analysis and interpretation. The database tables underlying the Genome Browser tracks can be viewed, downloaded, and manipulated using another Web-based application, the UCSC Table Browser. Users can upload data as custom annotation tracks in both browsers for research or educational use. This unit describes how to use the Genome Browser and Table Browser for genome analysis, download the underlying database tables, and create and display custom annotation tracks.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Karolchik, Donna and Hinrichs, Angie S. and Kent, W. James},
doi = {10.1002/0471142905.hg1806s71},
eprint = {NIHMS150003},
isbn = {4840000151304},
issn = {19348258},
journal = {Current Protocols in Human Genetics},
keywords = {Bam,Bioinformatics,Bioinformatics fundamentals,Biological databases,Comparative genomics,Genome analysis,Genome browser,Human genetics analysis,Human genome,Human variation,Next-gen sequencing,Table browser},
number = {SUPPL. 71},
pmid = {19957273},
title = {{The UCSC genome browser}},
year = {2011}
}
@article{Buenrostro2013,
abstract = {We describe an assay for transposase-accessible chromatin using sequencing (ATAC-seq), based on direct in vitro transposition of sequencing adaptors into native chromatin, as a rapid and sensitive method for integrative epigenomic analysis. ATAC-seq captures open chromatin sites using a simple two-step protocol with 500-50,000 cells and reveals the interplay between genomic locations of open chromatin, DNA-binding proteins, individual nucleosomes and chromatin compaction at nucleotide resolution. We discovered classes of DNA-binding factors that strictly avoided, could tolerate or tended to overlap with nucleosomes. Using ATAC-seq maps of human CD4(+) T cells from a proband obtained on consecutive days, we demonstrated the feasibility of analyzing an individual's epigenome on a timescale compatible with clinical decision-making.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Buenrostro, Jason D. and Giresi, Paul G. and Zaba, Lisa C. and Chang, Howard Y. and Greenleaf, William J.},
doi = {10.1038/nmeth.2688},
eprint = {NIHMS150003},
isbn = {5200401194},
issn = {15487091},
journal = {Nature Methods},
number = {12},
pages = {1213--1218},
pmid = {24097267},
title = {{Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position}},
volume = {10},
year = {2013}
}
@article{Edgar2002,
abstract = {The Gene Expression Omnibus (GEO) project was initiated in response to the growing demand for a public repository for high-throughput gene expression data. GEO provides a flexible and open design that facilitates submission, storage and retrieval of heterogeneous data sets from high-throughput gene expression and genomic hybridization experiments. GEO is not intended to replace in house gene expression databases that benefit from coherent data sets, and which are constructed to facilitate a particular analytic method, but rather complement these by acting as a tertiary, central data distribution hub. The three central data entities of GEO are platforms, samples and series, and were designed with gene expression and genomic hybridization experiments in mind. A platform is, essentially, a list of probes that define what set of molecules may be detected. A sample describes the set of molecules that are being probed and references a single platform used to generate its molecular abundance data. A series organizes samples into the meaningful data sets which make up an experiment. The GEO repository is publicly accessible through the World Wide Web at http://www.ncbi.nlm.nih.gov/geo.},
author = {Edgar, R.},
doi = {10.1093/nar/30.1.207},
isbn = {1362-4962 (Electronic)$\backslash$r0305-1048 (Linking)},
issn = {13624962},
journal = {Nucleic Acids Research},
pmid = {11752295},
title = {{Gene Expression Omnibus: NCBI gene expression and hybridization array data repository}},
year = {2002}
}
@article{Robinson2009,
abstract = {...  edgeR is a Bioconductor software package for examining differential expression of replicated count data . An overdispersed Poisson model is used to account for both biological and technical variability. ...},
author = {Robinson, M D and McCarthy, D J and Smyth, G K},
issn = {{\textless}null{\textgreater}},
journal = {Bioinformatics (Oxford, England)},
number = {1},
pages = {139--140},
title = {{edgeR: a Bioconductor package for differential expression analysis of digital gene expression data}},
url = {http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btp616{\%}5Cnpapers2://publication/doi/10.1093/bioinformatics/btp616},
volume = {26},
year = {2009}
}
@article{Love2014,
abstract = {In comparative high-throughput sequencing assays, a fundamental task is the analysis of count data, such as read counts per gene in RNA-seq, for evidence of systematic changes across experimental conditions. Small replicate numbers, discreteness, large dynamic range and the presence of outliers require a suitable statistical approach. We present DESeq2, a method for differential analysis of count data, using shrinkage estimation for dispersions and fold changes to improve stability and interpretability of estimates. This enables a more quantitative analysis focused on the strength rather than the mere presence of differential expression. The DESeq2 package is available at $\backslash$n                  http://www.bioconductor.org/packages/release/bioc/html/DESeq2.html$\backslash$n                  $\backslash$n                .},
archivePrefix = {arXiv},
arxivId = {arXiv:1303.3997v2},
author = {Love, Michael I. and Huber, Wolfgang and Anders, Simon},
doi = {10.1186/s13059-014-0550-8},
eprint = {arXiv:1303.3997v2},
isbn = {1465-6906},
issn = {1474760X},
journal = {Genome Biology},
pmid = {25516281},
title = {{Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2}},
year = {2014}
}
@article{Li2009,
abstract = {SUMMARY: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. AVAILABILITY: http://samtools.sourceforge.net.},
archivePrefix = {arXiv},
arxivId = {1006.1266v2},
author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard},
doi = {10.1093/bioinformatics/btp352},
eprint = {1006.1266v2},
isbn = {1367-4803$\backslash$r1460-2059},
issn = {13674803},
journal = {Bioinformatics},
pmid = {19505943},
title = {{The Sequence Alignment/Map format and SAMtools}},
year = {2009}
}
@misc{Morgan,
abstract = {This package provides an interface to the 'samtools', 'bcftools', and 'tabix' utilities (see 'LICENCE') for manipulating SAM (Sequence Alignment / Map), FASTA, binary variant call (BCF) and compressed indexed tab-delimited (tabix) files.},
author = {Morgan, Martin and Pag{\`{e}}s, Harv{\`{e}} and Obenchain, Valerie and Hayden, Nathaniel},
title = {{Rsamtools}}
}
@article{Fomel2009b,
abstract = {The articles in this special issue provide independent solutions for practical reproducible research systems. The use of Matlab-based tools such as the famous Wavelab and Sparselab packages in promoting reproducible research in computational harmonic analysis has been presented. In particular, the authors point to the success of the reproducible research discipline in increasing the reliability of computational research and reflect on the effort necessary for implementing this discipline in a research group and overcoming possible objections to it. An article also describes a Python interface to the well-known Clawpack package for solving hyperbolic partial differential equations that appear in wave propagation problems. The author argues strongly in favor of reproducible computations and shows an example using a simplified Python interface to Fortran code. An article also represents the field of bioinformatics, which has been a stronghold of reproducible research. It describes the cacher package, which is built on top of the R computing environment. Cacher enables a modular approach to reproducible computations by storing results of intermediate computations in a database. The special issue ends with an article on the legal aspects of reproducible research, including copyright and licensing issues.},
author = {Fomel, Sergey and Claerbout, Jon F.},
doi = {10.1109/MCSE.2009.14},
file = {:Users/inzirio/Library/Application Support/Mendeley Desktop/Downloaded/Fomel, Claerbout - 2009 - Reproducible Research.pdf:pdf},
issn = {1521-9615},
journal = {Computing in Science {\&} Engineering},
keywords = {reproducible research},
mendeley-tags = {reproducible research},
number = {1},
pages = {5--7},
pmid = {22144613},
title = {{Reproducible Research}},
volume = {11},
year = {2009}
}
@article{Kim2015,
abstract = {HISAT (hierarchical indexing for spliced alignment of transcripts) is a highly efficient system for aligning reads from RNA sequencing experiments. HISAT uses an indexing scheme based on the Burrows-Wheeler transform and the Ferragina-Manzini (FM) index, employing two types of indexes for alignment: a whole-genome FM index to anchor each alignment and numerous local FM indexes for very rapid extensions of these alignments. HISAT's hierarchical index for the human genome contains 48,000 local FM indexes, each representing a genomic region of ∼64,000 bp. Tests on real and simulated data sets showed that HISAT is the fastest system currently available, with equal or better accuracy than any other method. Despite its large number of indexes, HISAT requires only 4.3 gigabytes of memory. HISAT supports genomes of any size, including those larger than 4 billion bases.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Kim, Daehwan and Langmead, Ben and Salzberg, Steven L.},
doi = {10.1038/nmeth.3317},
eprint = {15334406},
isbn = {1548-7091},
issn = {15487105},
journal = {Nature Methods},
number = {4},
pages = {357--360},
pmid = {25751142},
title = {{HISAT: A fast spliced aligner with low memory requirements}},
volume = {12},
year = {2015}
}
@misc{Blankenberg2010,
abstract = {High-throughput data production has revolutionized molecular biology. However, massive increases in data generation capacity require analysis approaches that are more sophisticated, and often very computationally intensive. Thus, making sense of high-throughput data requires informatics support. Galaxy (http://galaxyproject.org) is a software system that provides this support through a framework that gives experimentalists simple interfaces to powerful tools, while automatically managing the computational details. Galaxy is distributed both as a publicly available Web service, which provides tools for the analysis of genomic, comparative genomic, and functional genomic data, or a downloadable package that can be deployed in individual laboratories. Either way, it allows experimentalists without informatics or programming expertise to perform complex large-scale analysis with just a Web browser.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Blankenberg, Daniel and Kuster, Gregory Von and Coraor, Nathaniel and Ananda, Guruprasad and Lazarus, Ross and Mangan, Mary and Nekrutenko, Anton and Taylor, James},
booktitle = {Current Protocols in Molecular Biology},
doi = {10.1002/0471142727.mb1910s89},
eprint = {NIHMS150003},
isbn = {0471142727},
issn = {19343639},
keywords = {Algorithm,Analysis,Bioinformatics,Galaxy,Genomics,Pipeline,SNPs,Workflow},
number = {SUPPL. 89},
pmid = {20069535},
title = {{Galaxy: A web-based genome analysis tool for experimentalists}},
year = {2010}
}
@article{Robinson2010,
abstract = {The fine detail provided by sequencing-based transcriptome surveys suggests that RNA-seq is likely to become the platform of choice for interrogating steady state RNA. In order to discover biologically important changes in expression, we show that normalization continues to be an essential step in the analysis. We outline a simple and effective method for performing normalization and show dramatically improved results for inferring differential expression in simulated and publicly available data sets.},
archivePrefix = {arXiv},
arxivId = {PMC2864565},
author = {Robinson, Mark D. and Oshlack, Alicia},
doi = {10.1186/gb-2010-11-3-r25},
eprint = {PMC2864565},
isbn = {1465-6906},
issn = {14747596},
journal = {Genome Biology},
pmid = {20196867},
title = {{A scaling normalization method for differential expression analysis of RNA-seq data}},
year = {2010}
}
@misc{Shepherd2018,
author = {Shepherd, Lori and Morgan, Martin},
title = {{BiocFileCache: Manage Files Across Sessions}},
year = {2018}
}
@misc{Gomez-Cabrero2014,
abstract = {To integrate heterogeneous and large omics data constitutes not only a conceptual challenge but a practical hurdle in the daily analysis of omics data. With the rise of novel omics technologies and through large-scale consortia projects, biological systems are being further investigated at an unprecedented scale generating heterogeneous and often large data sets. These data-sets encourage researchers to develop novel data integration methodologies. In this introduction we review the definition and characterize current efforts on data integration in the life sciences. We have used a web-survey to assess current research projects on data-integration to tap into the views, needs and challenges as currently perceived by parts of the research community.},
author = {Gomez-Cabrero, David and Abugessaisa, Imad and Maier, Dieter and Teschendorff, Andrew and Merkenschlager, Matthias and Gisel, Andreas and Ballestar, Esteban and Bongcam-Rudloff, Erik and Conesa, Ana and Tegn{\'{e}}r, Jesper},
booktitle = {BMC systems biology},
doi = {10.1186/1752-0509-8-S2-I1},
isbn = {10.1186/1752-0509-8-S2-I1},
issn = {17520509},
pages = {I1},
pmid = {25032990},
title = {{Data integration in the era of omics: current and future challenges}},
volume = {8},
year = {2014}
}
@article{Annunziato2008,
abstract = {The haploid human genome contains approximately 3 billion base pairs of DNA packaged into 23 chromosomes. Of course, most cells in the body (except for female ova and male sperm) are diploid, with 23 pairs of chromosomes. That makes a total of 6 billion base pairs of DNA per cell. Because each base pair is around 0.34 nanometers long (a nanometer is one-billionth of a meter), each diploid cell therefore contains about 2 meters of DNA [(0.34 × 10-9) × (6 × 109)]. Moreover, it is estimated that the human body contains about 50 trillion cells—which works out to 100 trillion meters of DNA per human. Now, consider the fact that the Sun is 150 billion meters from Earth. This means that each of us has enough DNA to go from here to the Sun and back more than 300 times, or around Earth's equator 2.5 million times! How is this possible?},
author = {Annunziato, Anthony T.},
journal = {Nature Education},
title = {{DNA Packaging: Nucleosomes and Chromatin}},
year = {2008}
}
@article{Trapnell2013,
abstract = {Differential analysis of gene and transcript expression using high-throughput RNA sequencing (RNA-seq) is complicated by several sources of measurement variability and poses numerous statistical challenges. We present Cuffdiff 2, an algorithm that estimates expression at transcript-level resolution and controls for variability evident across replicate libraries. Cuffdiff 2 robustly identifies differentially expressed transcripts and genes and reveals differential splicing and promoter-preference changes. We demonstrate the accuracy of our approach through differential analysis of lung fibroblasts in response to loss of the developmental transcription factor HOXA1, which we show is required for lung fibroblast and HeLa cell cycle progression. Loss of HOXA1 results in significant expression level changes in thousands of individual transcripts, along with isoform switching events in key regulators of the cell cycle. Cuffdiff 2 performs robust differential analysis in RNA-seq experiments at transcript resolution, revealing a layer of regulation not readily observable with other high-throughput technologies.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Trapnell, Cole and Hendrickson, David G and Sauvageau, Martin and Goff, Loyal and Rinn, John L and Pachter, Lior},
doi = {10.1038/nbt.2450},
eprint = {NIHMS150003},
isbn = {1750279917502799},
issn = {10870156},
journal = {Nature biotechnology},
number = {1},
pages = {46--53},
pmid = {23222703},
title = {{Differential analysis of gene regulation at transcript resolution with RNA-seq.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23222703{\%}0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3869392},
volume = {31},
year = {2013}
}
@article{McMurdie2013,
abstract = {BACKGROUND: the analysis of microbial communities through dna sequencing brings many challenges: the integration of different types of data with methods from ecology, genetics, phylogenetics, multivariate statistics, visualization and testing. With the increased breadth of experimental designs now being pursued, project-specific statistical analyses are often needed, and these analyses are often difficult (or impossible) for peer researchers to independently reproduce. The vast majority of the requisite tools for performing these analyses reproducibly are already implemented in R and its extensions (packages), but with limited support for high throughput microbiome census data.$\backslash$n$\backslash$nRESULTS: Here we describe a software project, phyloseq, dedicated to the object-oriented representation and analysis of microbiome census data in R. It supports importing data from a variety of common formats, as well as many analysis techniques. These include calibration, filtering, subsetting, agglomeration, multi-table comparisons, diversity analysis, parallelized Fast UniFrac, ordination methods, and production of publication-quality graphics; all in a manner that is easy to document, share, and modify. We show how to apply functions from other R packages to phyloseq-represented data, illustrating the availability of a large number of open source analysis techniques. We discuss the use of phyloseq with tools for reproducible research, a practice common in other fields but still rare in the analysis of highly parallel microbiome census data. We have made available all of the materials necessary to completely reproduce the analysis and figures included in this article, an example of best practices for reproducible research.$\backslash$n$\backslash$nCONCLUSIONS: The phyloseq project for R is a new open-source software package, freely available on the web from both GitHub and Bioconductor.},
archivePrefix = {arXiv},
arxivId = {Figures, S., 2010. Supplementary information. Nature, 1(c), pp.1–7. Available at: http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3006164{\&}tool=pmcentrez{\&}rendertype=abstract.},
author = {McMurdie, Paul J. and Holmes, Susan},
doi = {10.1371/journal.pone.0061217},
eprint = {/www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3006164{\&}tool=pmcentrez{\&}rendertype=abstract.},
isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {4},
pmid = {23630581},
primaryClass = {Figures, S., 2010. Supplementary information. Nature, 1(c), pp.1–7. Available at: http:},
title = {{Phyloseq: An R Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data}},
volume = {8},
year = {2013}
}
@article{Ihaka1996,
abstract = {In this article we discuss our experience designing and implementing a statistical computing language. In developing this new language, we sought to combine what we felt were useful features from two existing computer languages. We feel that the new lan- guage provides advantages in the areas of portability, computational efficiency, memory management, and scoping.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Ihaka, Ross and Gentleman, Robert},
doi = {10.1080/10618600.1996.10474713},
eprint = {arXiv:1011.1669v3},
isbn = {10618600},
issn = {15372715},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Computer language,Statistical computing},
pmid = {3279808},
title = {{R: A Language for Data Analysis and Graphics}},
year = {1996}
}
